
ATTENTION! If the formula display is broken, then reload the page. The search works only in the full browser version (it does not work in the mobile version).

Latest Pdf version of the Theory of everything: [Theory_of_everything.en(2024.04.26).pdf](Files/Theory_of_everything.en(2024.04.26).pdf)

## Cognition of the surrounding universe

### Irregularity of gravity. Quantum graviton. Blazar - SMBH with relativistic jets

Suppose if the gravity of [[SMBH.en|SMBH]] with [[Relativistic jet.en|relativistic jets]]([[Blazar.en|Blazar]]) is uniform. According to [[Albert Einstein.en|Albert Einstein's]] theory, gravity is only a deformation of space-time, that is, it can be represented for a two-dimensional case in the form of a highly stretched trampoline with a heavy ball/cannonball in the center. In this case, of course, we can immediately say that the formation of  [[Relativistic jet.en|relativistic jets]] is impossible, but scientists, as usual, come up with "crutches" so as not to throw the [[GTR.en|general theory of relativity (GTR)]] into the trash.

They make another assumption that the substance surrounding [[SMBH.en|SMBH]] does not have time to be absorbed. Although this assumption already contradicts [[GTR.en|GTR]], since for the space-time deforming SMBH it does not matter how much substance is around. SMBH according to GTR will absorb all the substance, as it will simply fall into SMBH. 
But let's still make the assumption that [[SMBH.en|SMBH]] does not have time to absorb the surrounding substance. Then the substance all arrives, and SMBH absorbs a small part of it. Substances near SMBH are increasing and it is layered on SMBH to form an outer shell. In this case, I would say that the shell should have such a density and gravity in the sum whit SMBH that light could not leave it. In fact, this would be a new SMBH layer.
However, scientists suggest the formation of an [[Accretion disk.en|accretion disk]] with a strong magnetic field, which, because of the [[Blandford–Znajek process.en|Blandford–Znajek process]] or [[Penrose process.en|Penrose process]], extracts energy from [[SMBH.en|SMBH]] and uses it to form [[Relativistic jet.en|relativistic jets]]. I'm sorry, what?! According to [[GTR.en|GTR]] , nothing can leave SMBH. So let's break the GTR and say it's possible. But energy is inseparable from matter. In fact, energy is a characteristic of matter. It is impossible to transfer energy without transferring particles and, as I will show later, gravity/[[Quantum graviton.ru|quantum gravitons]] is no exclusion either.

In fact, scientists assume the presence of [[Accretion disk.en|accretion disk]], which somehow forms a relativistic jet using the energy of [[SMBH.en|SMBH]]. And this is now the main explanation of what is happening with [[Blazar.en|blazar]].

It is assumed that the relativistic jet consists of plasma and magnetic fields act on it.

***Where do the particles of a relativistic jet come from? The only possible source candidates are SMBH and accretion disk. Suppose that the particles are taken not from SMBH, but from an accretion disk. What forces are acting on them? SMBH gravity, as well as gravity and assumed magnetic field of the accretion disk. Scientists assume the presence of a very strong magnetic field by the accretion disk. In this case, the accretion disk is actually similar in effect to a ring with a current with a well-known magnetic field structure (figure 1).***  

![[pic7.jpg]] 

**Figure 1 – The structure of the magnetic field of a ring with a current**

***Accordingly, this means that there is no force capable of accelerate the particles of the accretion disk along the axis of flight of relativistic jets. In addition, up to speeds close to the speed of light. Moreover, with strong magnetic fields, the accretion disk should have a defocusing effect on the plasma of relativistic jets, what is not observed in reality.***

***As a result of the influence by SMBH and by accretion disk, according to GTR, it cannot lead to the formation of relativistic jets. Moreover, the total force/influence pulls the particles into the SMBH.***

***And now let's figure out how it really works.***

The data [[LIGO.en|LIGO]] is extremely important to us for this. In 2016, LIGO collaborations announced the discovery of gravitational waves. In fact, during the observation, a significant change in the gravitational field was recorded that fell on different detectors at different times. Based on this, the radiation source was calculated and discovered. The signal came from the merger of two black holes at a distance of about 1.3 billion light years (~$10^{25}$ meters). At the same time, a significant part of their mass (about 3 times the mass of the Sun) was spent on radiation in ~ 0.2 seconds. However, in our galaxy ([Milky way](https://en.wikipedia.org/wiki/Milky_Way) ) approximately half of all stars belong to [binary stars (binary systems)](https://en.wikipedia.org/wiki/Binary_star) which are much closer to us. Nearest [Alpha Centauri](https://en.wikipedia.org/wiki/Alpha_Centauri) at a distance of about 4.36 light years (~$4 ⋅ 10^{16}$ meters). Moreover, the effect of gravitational influence decreases in proportion to the square of the distance. All this indicates that the key role in the formation of gravitational waves is played not by the proximity of the binary system and not by the mass of objects, but by the magnitude of the changing radiation of [[Quantum graviton.en|gravitons]].

According to [[GTR.en|GTR]], gravity is a deformation of space-time without energy transfer (it does not have a force effect), but the loss of energy to gravitational radiation ([gravitational waves](https://en.wikipedia.org/wiki/Gravitational_wave)) in close binary systems is also, according to the statement, in good conform with the GTR model. In fact, if we take any real objects of the universe that have mass, then each pair of them is also a binary system, and therefore objects lose energy to gravitational radiation (gravitational waves). It's just that the speed of processes and the magnitude of gravitational radiation are not as large as in close binary systems. Based on this, for example, even a hydrogen atom is a binary system of electron-proton and generates gravitational radiation. This means that even according to GTR ***all objects of the universe (which having mass) generate gravitational radiation, spend energy on it and exert a force effect on surrounding objects***.

And now the main thing. Let's assume that gravity is not a field created by mass (not a deformation of space-time from [[GTR.en|GTR]]), but elementary particles constantly emitted by objects that having mass ([[Quantum graviton.en|gravitons]]).
In the case of merging black holes (detected by LIGO), there was a rapid change in the magnitude of gravitational radiation. In fact, a significant part of the gravitons, that make up these black holes, were emitted in a very short period of time (~0.2 seconds).

What we have. Two black holes merging emitted a huge amount of [[Quantum graviton.en|gravitons]] in a short period of time, which we recorded thanks to [[LIGO.en|LIGO]]. We also realized that the speed of propagation of gravitons is equal to the speed of light.

Then how does operate [[SMBH.en|SMBH]] with [[Relativistic jet.en|relativistic jets]]([[Blazar.en|Blazar]])? 
The whole point is that gravitons, like photons, can be emitted unevenly. ***SMBH with relativistic jets (Blazar) emits gravitons unevenly. The maximum amount of graviton radiation is in the plane of the galaxy, and the minimum is perpendicular to it. It turns out that the radiation in the minimum is so small that part of the matter from the SMBH flies out and forms jets (relativistic jets) of the blazar.***
Why is there such an uneven emission of gravitons for some SMBH? Apparently, the whole point is in the rotation of the SMBH around its own axis at relativistic speeds. Imagine a children's carousel spinning at high speed. If things, pebbles and even dust particles are lying on it, then they will scatter in a plane perpendicular to the axis of rotation. Apparently this is what happens with SMBH rotating at a speed approaching to the speed of light.

#### Dark matter

Does dark matter exist? 
[[Blazar.en|Blazars]] and [[LIGO.en|LIGO]] indicate that the radiation of gravity may be uneven.
The maximum amount of graviton radiation is in the plane of the galaxy, and the minimum is perpendicular to it. It turns out that the radiation in the minimum is so small that part of the matter from the supermassive black hole flies out and forms jets (relativistic jets) of the blazar. Why is there such an uneven emission of gravitons for some supermassive black hole? Apparently, the whole point is in the rotation of the supermassive black hole around its own axis at relativistic speeds.

As a result, the density of gravitational radiation falls out of proportion to the square of the distance. The decrease of density of gravitational radiation is in the range from the proportion of the distance to the proportion of the square of the distance. More precisely, the dependence is determined by the redistribution of radiation from a rotating supermassive black hole in the center of the galaxy. To be more precise, the density of the gravitational stream is determined by the totality of uneven radiation from all objects of the galaxy.

We get that there may be no need to add theoretical dark matter. Everything is explained by the uneven emission of gravitons.

### All elementary particles = quantum photons and quantum gravitons. What the elements of the Standard Model consist of. The disintegration of everything in the universe

Due to the fact that we have isolated [[Quantum graviton.en|quantum graviton(q.g.)]] as a separate elementary particle, it is now possible to answer the question of what the whole universe consists of. The answer is simple - from [[Quantum photon.en|quantum photons(q.ph.)]] and [[Quantum graviton.en|quantum gravitons(q.g.)]].

All elements of [[Standard Model.en|Standard Model]] consist of [[Quantum photon.en|quantum photons(q.ph.)]] and/or [[Quantum graviton.en|quantum gravitons(q.g.)]].
The simplest proof is the annihilation processes, for example, of an electron-positron pair, while are formed [[Photon.en|photons]] and gravitons, which are difficult to detect.
In fact, an electron and a positron consist of a bunch of quantum photons and quantum gravitons, but during interaction/annihilation/"transformation" they lose stability and fly apart into their constituent parts. Each "formed" of 2/3 [[Photon.en|photons]] contains many quantum photons.
All the "transformations" of particles [[Standard Model.en|Standard Model]] plus a quantum gravitons - changing combinations of groups [[Quantum photon.en|quantum photons(q.ph.)]] and [[Quantum graviton.en|quantum gravitons(q.g.)]]. 

Everything with mass contains and emits quantum gravitons. Everything that has a charge contains and emits quantum photons. Everything that has a neutral charge and a non-zero mass contains and emits on average an equal number of quantum photons with opposite helicity (they carry the opposite charge effect). As a result, everything consists of a quantum photons and a quantum gravitons.

It is worth noting that such stable particles as, for example, a proton are not really absolutely stable, since they have mass and, accordingly, emit [[Quantum graviton.en|quantum gravitons]] and if there are no external sources for sufficient replenishment, they will decay. Also with black holes.

As you know, [[Photon.en|photons]] are distinguished by their [[Helicity.en|helicity]] (projection of the spin on their movement). Apparently, helicity is responsible for the positivity/negativity of the charge/effect carried by the photon. That is, an electron and a positron differ in that they include photons with different helicity, or rather [[Quantum photon.en|quantum photons]] with different helicity. The same is true for all other particles and their antiparticles.

To shorten , we will write $q.ph.^+$ (quantum photon with positive [[Helicity.en|helicity]]) and $q.ph.^-$ (quantum photon with negative [[Helicity.en|helicity]]).

As a result, everything consists of [[Quantum photon.en|quantum photons(q.ph.)]] and [[Quantum graviton.en|quantum gravitons(q.g.)]]. All the "conversions"/transformations/decays of particles [[Standard Model.en|Standard Model]] and their derivatives are nothing but the redistribution of quantum photons and quantum gravitons. 
Antimatter is essentially just another combination of ordinary matter ([[Quantum photon.en|quantum photons]] in them have an inverted [[Helicity.en|helicity]], that is, where they were $q.ph.^+$ are located $q.ph.^-$, and where were $q.ph.^-$ are located $q.ph.^+$).
A proton actually consists of a positron and a neutral charge residue. And the neutral charge residue contains an equal number of quantum photons with opposite helicity (on average). 

Based on the fact that all substance/matter/antimatter of the universe as a whole is electroneutral, this means that it consists on average of an equal amount of $q.ph.^+$ and $q.ph.^-$, as well as some quantity of $q.g.$
Due to the fact that galaxies constantly emit $q.ph.^+$, $q.ph.^-$ and $q.g.$ beyond their conditional boundaries and this happens along the outer perimeter of the matter/antimatter of the universe, then eventually, over time, all matter/antimatter will be divided into elementary components - $q.ph.^+$, $q.ph.^-$ and $q.g.$. If the system with time loses some of its components to the "external" space, then the stock of these components will decrease, which will eventually lead to the inability to maintain a stable state and the separation of the system into elementary components.

### Positrons and electrons

Positrons emit/contain exclusively [[Photon.en|photons]] consisting of $q.ph .^+$.
Electrons emit/contain exclusively [[Photon.en|photons]] consisting of $q.ph .^-$.

The reasons for these conclusions are given below.

Suppose a positron consists exclusively of $q.ph .^+$ and $q.g.$. When "absorbing" $photon^-$ (groups $q.ph .^-$) positron, or rather $q.g.$ in it invert [[Helicity.en|helicity]] $q.ph .^-$ to $q.ph .^+$ with the opposite velocity vector (the momentum vector also becomes opposite), which explains the further dynamics of the positron. When "absorbing" $photon^+$ (groups of $q.ph .^+$) the positron is actually just joined by an additional group of $q.ph .^+$ with the same velocity vector.
Similarly for the electron.
Suppose an electron consists exclusively of $q.ph .^-$ and $q.g.$. When "absorbing" $photon^+$ (groups $q.ph .^+$) an electron, or rather $q.g.$ in it invert [[Helicity.en|helicity]] $q.ph .^+$ to $q.ph .^-$ with the opposite velocity vector (the momentum vector also becomes opposite), which explains the further dynamics of the electron. When "absorbing" $photon^-$ (groups of $q.ph .^-$)  the electron is actually just joined by an additional group of $q.ph .^-$ with the same velocity vector.

In fact, the question here is "can a quantum photon change [[Helicity.en|helicity]] when interacting with [[Quantum graviton.en|quantum gravitons]]?".

If not. Then the positron can emit a group $q.ph .^-$($photon^-$), which was previously absorbed and included in its structure. In this case , it may include both $q.ph .^+$ and $q.ph .^-$ linked together owing to $q.g.$. Then if you constantly let $photon^-$ (groups of $q.ph .^-$) into the positron, then $q.ph .^-$ will become more than $q.ph .^+$ and the positron will "turn" into an electron? In such a situation, positrons will not be interchangeable, since they will have different amounts of $q.ph .^+$ and $q.ph .^-$ and, accordingly, their behavior will be different. It turns out that the state between the positron and the electron will be blurred and depends on the ratio $q.ph .^+$ and $q.ph .^-$. Let's consider a hydrogen atom for this case. The electron will constantly receive $q.ph .^+$ from proton, and proton $q.ph .^-$ from the electron. Then the amount of excess radiation $q.ph .^-$ from the electron and $q.ph .^+$ from the proton will decrease in time and soon both particles will become electroneutral (at least one particle will become electroneutral) and the atom will split into electroneutral parts.
The universe is on average electroneutral, and therefore all charged particles will exchange on average the same flow $q.ph .^+$ and $q.ph .^-$. In this case, positively charged particles will initially emit mainly $q.ph .^+$, and negatively charged particles will initially emit mostly $q.ph .^-$. Further, all charged particles will quickly lose the individuality of the charge and become electroneutral.
All this does not correspond to the observed dynamics of the electron, positron and other charged particles.

As a result, we get that a quantum photon can change [[Helicity.en|helicity]] when interacting with [[Quantum graviton.en|quantum gravitons]].
Positrons emit/contain exclusively [[Photon.en|photons]] consisting of $q.ph .^+$.
Electrons emit/contain exclusively [[Photon.en|photons]] consisting of $q.ph .^-$.
When absorbing/joining $q.ph.$ with the opposite [[Helicity.en|helicity]] to the positron/electron - helicity is inverted and the velocity vector is also inverted (more complex charged particles actually consist of a positron/electron and a neutral residue. For example, a proton consists of a positron and a neutral residue).

### Properties of quantum photon and quantum graviton. Diffraction. Observer effect. Dynamics of elementary particles is predetermined. Fate

Now you need to understand the properties of $q.ph .$ and $q.g.$.
They are corpuscles, not waves. 

Slit or half-plane diffraction and other effects are easily explained by the fact that photons/electrons or other particles collide with an obstacle/slit and are re-emitted by particles of this obstacle/slit. This is also true for single photons/particles from the source.

The observer effect is also easily explained by the fact that by "observing" we influence the slit/obstacle and thereby disrupt the natural process of photon/particle re-emission from the source by the slit/obstacle particle system. As a result, although the human eye is an "observer", it does not affect the processes of re-emission of particles, since it does not have an active impact, but only fixes [[Photon.en|photons]] falling into it. On the contrary, if you exert an active influence, the process of re-emission will change. If we influence the system, we get a different result of particle dynamics. No magic.

So $q.ph.$ and $q.g.$ are elementary particles, and the presence of consciousness/passive observer does not affect to the systems even at the level of elementary particles. The laws of elementary particle dynamics are immutable and clearly defined. And this leads us to the fact that there are no random events. It's just that sometimes we don't know all the initial conditions and the exact laws of elementary particle dynamics ($q.ph .^+$, $q.ph .^-$ and $q.g.$).
As a result, the dynamics of the elementary particles of the universe is predetermined. Every time I think about it, I get a feeling of discomfort, because it turns out that I have no choice and my whole life is fate. But these are the laws of our world. Nothing can be done about this fact. 

### Particle stability. Proton-proton cycle. Neutron decay

Let's return to the false stability of the particles. Consider a proton. Now we cannot create ideal isolation conditions under which the access of the recharge will be completely blocked $q.ph .^+$, $q.ph .^-$ and $q.g.$. However, consider nuclear reactions in stars. In particular, the proton-proton cycle. 
$$ p + p → ^2H + e^+ + ν_e $$
At the level of quarks: $u → d + e^+ + ν_e$.
So two protons interact and exchange components $q.ph .^+$, $q.ph .^-$ and $q.g.$ are transformed into the nucleus of the hydrogen isotope deuterium (deuteron), positron and electron neutrino. In fact, one proton is divided into a neutron, a positron and an electron neutrino.
Now it is clear what the proton consists of. The composition of the neutron includes $q.g.$ and an equal amount of $q.ph .^+$ and $q.ph .^-$. The positron consists of $q.ph .^+$ and $q.g.$. The electron neutrino is well described by its name - a small neutron. The neutrino composition also includes $q.g.$ and an equal amount of $q.ph .^+$ and $q.ph .^-$.
As a result, free protons will also decay when recharge decreases $q.ph .^+$, $q.ph .^-$ and $q.g.$.

Particles and antiparticles differ only [[Helicity.en|helicity]] of $q.ph .$. If, for example, in the particle is dominated by $q.ph .^+$, then there is an inversion in the antiparticle, that is $q.ph.^-$

We have seen earlier how in the nuclear reactions of stars, a proton actually decays into a positron, a neutron and an electron neutrino. And what a neutron usually decays into. On the proton, electron and electron antineutrino.
$$ p^+ → n + e^+ + ν_e \text{ (At the level of quarks: } u → d + e^+ + ν_e \text{ ) } $$
$$ n → p^+ + e^- + \overline ν_e \text{ (At the level of quarks: } d → u + e^- + \overline ν_e \text{ ) } $$
The beauty is when these two decays are written side by side.
As we can see, particles and antiparticles are part of what are considered ordinary particles of matter.
The electroneutrality of the universe indicates that the amount of $q.ph .^+$ and $q.ph .^-$ is equal.
Interestingly, in both decays, the resulting neutron and proton contain a smaller amount of $q.ph.^+$, $q.ph.^-$ and $q.g.$ than the original proton and neutron. The missing part goes to the positron and electron, electron neutrinos and antineutrinos, respectively. I wonder if in the end the chain of decays: neutron → proton → neutron → proton → and so on with residues in the form of electrons, positrons, neutrinos, antineutrinos will last as long as there is a reserve $q.ph.^+$, $q.ph.^-$ and $q.g.$? Maybe, but that's not the main thing here. Adding up these two decays:
$$ p^+ + n → n + p^+ + e^+ + e^- + ν_e + \overline ν_e → n + p^+ + \gamma  + \text{ q.g.
 } $$
(we have not yet learned how to detect quantum gravitons normally)
we get a neutron and a proton from a proton and a neutron, and also in the process of annihilation of positron-electron pairs, electron neutrinos-antineutrinos we get $q.ph .^+$, $q.ph .^-$ and $q.g.$.

Consider the annihilation of proton and antiproton $p+ \overline p$ (I prefer the notation form: $p^++p^-$):
$p^++p^- → 2π^+ + 2π^- + 3π^0 →$$2(μ^+ + ν_μ) + 2(μ^- + \overline ν_μ) + \gamma →$$2(e^+ + \overline ν_μ + ν_e + ν_μ) + 2(e^- + ν_μ + \overline ν_e + \overline ν_μ) + \gamma →$$2(e^+ + e^-) + 4(ν_μ + \overline ν_μ) + 2(ν_e + \overline ν_e) + \gamma →$$\gamma$

We get a lot of photons as a result (in fact, we get a lot of $q.ph .^+$, $q.ph .^-$ and $q.g.$).

As you can see, the proton is not an elementary particle (it consists of $q.ph .^+$, $q.ph .^-$ and $q.g.$) and is unstable (additional explanations in the section «[[theoryofeverything.en#Stability of elementary particle systems|Stability of elementary particle systems]]»). 
As a result, we again come to the conclusion that everything consists of $q.ph .^+$, $q.ph .^-$ and $q.g.$.

### Feature of the neutrino structure. Photon structure

Neutrinos are very specific particles of the Standard Model due to their weak interaction with matter. Neutrinos in this plan are similar to [[Quantum graviton.en|quantum gravitons]]. However, possible transformations of the electron-positron pair in both [[Photon.en|photons]] and neutrino-antineutrino:
$$ e^+ e^- → 2 \gamma $$
$$ e^+ e^- → ν \overline ν $$
indicates that they also consist of $q.ph .^+$, $q.ph .^-$ and $q.g.$.
This is also indicated by many other chains of transformations, for example, the annihilation of an electron-positron pair at high energies. In this case, intermediate pi mesons are formed first, and then neutrinos are formed from them, among other things:
$$ e^+ e^- → π^+ π^- → μ^+ + μ^- + ν_μ + \overline ν_μ $$
The uniqueness of neutrinos lies in their structure, compared to other particles of the Standard Model. $Q.ph .^+$, $q.ph .^-$ and $q.g.$ in neutrinos are very compactly/densely packed, which leads to much rarer collisions with matter/antimatter and, respectively, the colossal mean free path.

As we know, an electron-positron pair can transform into a neutrino-antineutrino pair:
$$ e^+ e^- → ν \overline ν $$
So it is the structure of the particle packaging that so strongly influences the interaction/collisions with other particles.

The structure of [[Photon.en|photon]] is also extremely interesting. A photon consists of a group $q.ph .$, which seems to form the shape of a disk or circle. It is because of this the light can be polarized, that is, certain spatial orientations of disks cannot be skipped.

### ImFR

**Immobile frame of reference (ImFR)** are reference frames in which immovable objects are at rest, and free photons that do not interact with surrounding particles move at the same speed of light. ImFR are equal and can be described by general laws.

The speed of an arbitrary clock relative to the ImFR is apparently equal to the speed relative to [relic radiation](https://en.wikipedia.org/wiki/Cosmic_microwave_background)(based on the [dipole anisotropy](https://en.wikipedia.org/wiki/Dipole_anisotropy)).

### Effect time dilation of a moving clock compared to a rest one in ImFR

Now let's consider an experiment in which a moving clock is delayed compared to a rest one  – [[Hafele–Keating experiment.en|Hafele–Keating experiment]]. For simplicity, we will consider a light clock. According to the Theory of Relativity, the effect of "time dilation" is used to describe the effect of the delay of the clock. However, when using ImFR, this is not required, since in reality there is no "time dilation" effect.

![[pic1.png]]

a) the clock is at rest; b) the clock is moving at speed v, the photon is moving in the direction of movement of the clock; c) the clock is moving at speed v, the photon is moving in the opposite direction of movement of the clock.
**Figure 2 – Effect time dilation of moving clocks compared to those at rest in the ImFR**

The clock is resting (Figure 2a). In order for the photon to "pass" the path from the first plate to the second and back, it takes time $T=\frac{2L}{c}$ – this is the period of hours. By the number of periods, they determine how much time has passed, since they consider the period immutable

The clock moves at a speed of v (Figure 2b, 2c). Then, when the photon moves in the direction of the movement of the clock, it will need to pass a distance greater than L, since the clock moves at a speed v relative to the ImFR.  The distance will be equal to $cT_1=vT_1+L$, from where $T_1=\frac{L}{c-v}$. When the photon moves in the opposite direction of the clock, it will need to travel a distance less than L. The distance will be $cT_2=L-vT_2$, from where $T_2=\frac{L}{c+v}$.

We get that the time of the full period $T=T_1+T_2=\frac{L}{c-v}+\frac{L}{c+v}$ Then at zero clock speed: $T=\frac{2L}{c}$, at a clock speed of 0.5c: $T=\frac{2L}{c}+\frac{2L}{3c}=\frac{8L}{3c}$, and at the speed of the clock tending to the speed of light: T→∞.

As a result, the moving clock counts down fewer cycles of the "periodic" process, since the time spent on each cycle is longer. This leads to the fact that the moving clock is delayed compared to the rest or moving at a slower speed.

Time is a characteristic of the world, reflecting the change in the location of elementary particles in space.

Time is the same for all objects and flows continuously, linearly, and most importantly, does not depend on anything. The closest to reality are the understandings of time as the "arrow of time" and the "axis of time", but it is not possible to move along this axis, since for this it is necessary to be able to control elementary particles and world laws, that is, the world.

"Time dilation", other effects of the Theory of Relativity [[Albert Einstein.en |Einstein]] and the theory itself originate from a physically erroneous definition of the term "Time". Why it is physically wrong to give an appropriate definition is described in the section "How to define the term "Time" in order to create a theory of relativity".

### How to define the term "Time" in order to create a theory of relativity

Date of initial publication in Russian: 02.08.2015

Since 1967, the international system of units ([SI](https://en.wikipedia.org/wiki/International_System_of_Units)) has defined a second as 9 192 631 770 periods of electromagnetic radiation that occurs during the transition between two hyperfine levels of the ground state of the caesium-133 atom.

However, on what basis is it considered that the period of electromagnetic radiation does not depend on anything?

An example of rational thoughts in this direction is the fact that clarifications have been added to the above definition of a second since 1997: at rest, at a temperature of 0 K and in the absence of external fields. However, these refinements are not applied in practice, since atomic clocks are not at a temperature of 0 K and are not at rest, since the Earth's surface is not even close to the inertial frame of reference (IFR).

Consider the fact:

Clock No. 1, moving at a higher speed relative to a immobile frame reference (ImFR) or IFR, counts fewer periods than clock No. 2, moving at a lower speed.

Conclusion (according to [[GTR.en|GTR]]):

1. When the speed of the clock/object is higher (relative to IFR), then stronger the time dilation (time deformation);
2. The time spent on the period of electromagnetic radiation (the time of the full period) does not change.

Conclusion (according to my concept):

1. When the speed of the clock/object is higher (relative to the ImFR), then longer the period of electromagnetic radiation (the time of each period increases). The flow of time is invariable (constantly). There is no exist time dilation;
2. The time spent on the period of electromagnetic radiation (the time of the full period) varies.

Both interpretations are based on the same fact, but completely opposite.

The interpretation described from the point of view of GTR is the fundamental, key basis of GTR, without which its existence is impossible.

The interpretation described from my point of view testifies to the absolute nature of time and the world as a whole.

#### The concept of time

Unit of time. In a time equal to one second, a quantum of light (photon) that does not interact with anything passes a distance of 299,792,458 m.

The periodicity of processes in arbitrary clocks (objects), including atomic or light ones, depends on the speed of movement of the clock relative to the ImFR. When the movement speed of the clock is higher, then more time is spent on the period of electromagnetic radiation (for example, the caesium-133 atom) or the full period of the light clock.

In the extreme case, with the movoment speed of the clock tending to the speed of light, the period of electromagnetic radiation tends to infinity (see [[theoryofeverything.en#Effect time dilation of a moving clock compared to a rest one in ImFR|Effect time dilation of a moving clock compared to a rest one in ImFR]]). 

As a result, with an increase in the speed of the object, not time slows down/dilates, but the time of the period of processes in the object increases (for example, the period of electromagnetic radiation).

Time flows the same for all elementary particles and their systems (all objects of the world).

One of the main problems of GTR is precisely that it is taken on faith that the period of electromagnetic radiation (clock cycle) is constant (not changed) and does not depend on anything.

The period of electromagnetic radiation in an atomic clock is the average time between two radiations of an atom (for example, caesium–133).

The period of light clocks is the time during which a quantum of light flies from the first plate to the second and back.

It is particularly worth noting that the [Michelson-Morley experiment](https://en.wikipedia.org/wiki/Michelson%E2%80%93Morley_experiment) is not indicative, since it cannot be guaranteed that the process of re-emitting light by mirrors takes the same time. However, it is presented as an irrefutable proof of the correctness of GTR, which it is not.

In fact, the definition of a second (adopted since 1967 and refined in 1997) depends on the speed movement of the clock relative to the ImFR, since the time spent on each period of electromagnetic radiation changes.

As a result, according to the currently accepted definition of "Time", the duration of a second is different for objects moving at different speeds.

Actually, using the term "Time", which depends on the speed of movement of the clock / object, the GTR turned out.

By introducing a dependence on speed in the definition of time, we obtained a dependence in the form of a relativistic "time dilation". The whole essence of GTR is generated by the term "Time".

What are the possible options for checking the stability of the period of electromagnetic radiation of an atom and, accordingly, the term "Time"?

According to GTR, a moving clock in any IFR should go slower than a rest one. This can be checked and it can be obtained that in certain cases the clock will go faster, namely when it will move slower in ImFR.

According to the generally accepted definition of a second (9 192 631 770 periods of radiation of the caesium-133 atom), light will travel 299,792,458 m, but for clocks moving at different speeds (relative to ImFR), the distance traveled by light per second in ImFR (absolute time interval) will be different. This will indicate the different duration of the period in clocks.

We get the key question: how to determine the absolute time / absolute time interval / time in ImFR?

1.  Measure the time it takes for light to travel a distance of 299,792,458 m in ImFR. A very difficult task.
2.  Based on the description [[theoryofeverything.en#Effect time dilation of a moving clock compared to a rest one in ImFR|Effect time dilation of a moving clock compared to a rest one in ImFR]], the period of the clock, for example light clocks, where $v$ is the speed of the clock relative to ImFR, can be determined by the formula:
    $\large{T = \frac{L}{c-v}+\frac{L}{c+v}}(1)$ 
    
    Period of clocks in ImFR: 
    $\large{T_{ImFR} = \frac{2L}{c} (2) => L = \frac{cT_{ImFR}}{2}}(3)$ 
    
    Substitute (3) in (1):
    $\large{T = \frac{cT_{ImFR}}{2(c-v)}+\frac{cT_{ImFR}}{2(c+v)} = \frac{cT_{ImFR}(c+v)}{2(c-v)(c+v)}+\frac{cT_{ImFR}(c-v)}{2(c-v)(c+v)} =}$  $\large{\frac{c^2T_{ImFR}}{(c-v)(c+v)} (4)}$ $\large{=>}$ $\large{T_{ImFR} = \frac{T(c-v)(c+v)}{c^2}}(5)$   

Now it is important to answer the following question. What does any clock show? Time? No. The number of periods multiplied by a constant.

The period of an arbitrary clock (T) depends on all external influences, temperature and, most importantly, on the speed movement of the clock relative to ImFR.

At the same time, the number of periods for arbitrary clock:
$\large{M = \frac{t}{T} = t \frac{(c-v)(c+v)}{c^2T_{ImFR}}}(6)$,

from where we get:
$\large{T_{ImFR} = t \frac{(c-v)(c+v)}{c^2M}}(7)$ 

At the same time, the number of periods in the ImFR:
$\large{N = \frac{t}{T_{ImFR}}}(8)$.

Substitute (7) into (8) and get the constant number of periods in the ImFR, which does not depend on the speed of an arbitrary clock:
$\LARGE{N = \frac{t}{T_{ImFR}} = \frac{t}{t\frac{(c-v)(c+v)}{c^2M}} = \frac{c^2M}{(c-v)(c+v)}}(9)$.

In fact, in this way it is possible to calculate the absolute time for arbitrary clocks. However, it is worth remembering that it is necessary to consider the dependence of the clock on all external influences and temperature, and also here we consider an idealized light clock, not a real atomic one.

It is worth remembering that here $v$ is the speed of an arbitrary clock relative to ImFR.

Apparently $v$ is the speed relative to zero shift of the [relic radiation](https://en.wikipedia.org/wiki/Cosmic_microwave_background)(zero [dipole anisotropy](https://en.wikipedia.org/wiki/Dipole_anisotropy)).

So, what if the period of electromagnetic radiation is not constant and depends on the speed of the clock relative to the ImFR?

1.  Time (based on the term of my concept) is an absolute quantity, as is space and the whole world as a whole (including elementary particles, their characteristics and the systems they make up), as well as all the consequences that follow from this.
2.  There is no need to make conversions when switching between IFR. IFR are no longer needed at all. Each object moves relative to a single ImFR.
3.  There are no "time dilations", "length reductions", "relativity of simultaneity" and GTR in general.

#### Result

Or we consider that the period of the clock does not depend on the speed of their movement relative to the ImFR and is the same in all IFRs, and then we define the term "time" based on a fixed number of periods of electromagnetic radiation of the caesium-133 atom, and we get GTR.

Or we agree that clocks moving at different speeds relative to the ImFR show different times due to the fact that the period of processes in them is different, and we get an absolute world.

I consider that the facts indicate the dependence of the period of all internal processes (in particular, the period of electromagnetic radiation of the caesium-133 atom) on the speed of the object/system of elementary particles relative to the ImFR.
In fact, when the speed of an object/system of elementary particles is closer to the speed of light, then lower the relative speed between its elementary particles and, accordingly, more time is spent on all processes.
In the extreme case, when the speed relative to ImFR tends to the speed of light, any elementary particles of the object/system will never interact (for example, a quantum graviton moving from one quantum photon to another will never reach it, since the projection of the speed in the desired direction will tend to zero - [[theoryofeverything.en#Dependence of the period of processes in the object on the speed of movement of the object relative to ImFR|dependence of the period of processes in the object on the speed of movement of the object relative to ImFR]]).

### Dependence of the period of processes in the object on the speed of movement of the object relative to ImFR 

The speed of an object strongly affects its dynamics, since the period of all processes tends to infinity when the speed (relative to ImFR) tends to the speed of light. The period of the processes increases due to the fact that the velocity vectors, $q.ph .^+$, $q.ph .^-$ and $q.g.$. as parts of an object, tend to be co-directed. And in order for, for example, $q.g.$ fly from one $q.ph._1$ to another $q.ph._2$, it takes a very long time, since the projection of the velocity of $q.g.$ to the desired direction is extremely small (tends to zero when the speed of the object (relative to ImFR) tends to the speed of light):

![[pic2.en.jpg]] 

**Figure 3 – Interaction of two quantum photons with a quantum graviton when the object's speed (relative to ImFR) tends to the speed of light**

At zero object speed (relative to ImFR), the process period is minimal. Hence we get that when the speed of an object increases (relative to ImFR), then increase its lifetime (relative to ImFR). This is actually confirmed experimentally. When the speed of an unstable particle/object is closer to the speed of light (relative to ImFR), then greater the distance it passes before decaying.

### The inequality of inertial reference frames of the universe 

The theory of relativity is mathematically beautiful and consistent. However, it is possible to describe many variants in which the solution of the problem by its means will be real experimentally in one inertial frame of reference, but impossible in practice in another inertial frame of reference. The reason for this is that different inertial frames of reference are unequal and do not reflect reality when trying to describe by the general laws.

[[UnsolvedTwinParadoxLight.en|The inequality of inertial reference frames of the universe]] is described in a separate article.
### [General theory of relativity vs gravitational maneuvers and black holes](http://howallworks.github.io/blog/2015/11/obshchaia-teoriia-otnositelnosti-vs-gravitatsionnye-manevry-i-chernye-dyry.html)

Date of initial publication in Russian: 22.11.2015

[Gravitational maneuver (GM)](https://en.wikipedia.org/wiki/Gravity_assist) – acceleration, deceleration, change in the direction of an object's flight under the influence of the gravitational fields of other objects, usually massive (cosmic objects)

During a gravitational maneuver, the velocity vector and the magnitude of the momentum and the energy of the target object change, that is, these parameters before GM and after GM are different.

This is true for any frame of reference (FR), including inertial frame of reference (IFR), based on data on the dynamics of objects in the universe and the results of numerical modeling. Except for the case when FR is associated with a massive object ($MO_1$), due to which the gravitational maneuver is carried out. However, even in this privileged case, if there is at least one other massive object ($MO_2$) having a non-zero speed (relative to $MO_1$), which corresponds to all real cases, the parameters of momentum and energy will change for the target object using the gravitational maneuver as in other cases. Changes in these parameters occur due to the fact that whichever of the massive objects is selected for FR, the other massive objects will contribute to changing the parameters of the target object using GM. As a result, we found out that for all real cases, the gravitational maneuver leads to a change in the velocity vector and the magnitude of the momentum and energy of the target object.

According to the general theory of relativity (GTR), gravity is not a force, but a deformation of space-time, in which there are no forces, particles-carriers of interaction and, accordingly, the exchange/transfer of energy. However, as it was shown earlier, the energy of the target object changes due to gravity (in the absence of other forces) in the case of GM. This means that gravity exerts a force effect, as a result of which the energy of the target object changes. It also means that the representation of gravity in the form of a deformation of space-time according to GTR is erroneous, since in reality the energy of the target object changes during a gravitational maneuver.

Some important consequences:

- gravity is  transported by particles – gravitons. Based on the available data, the speed of gravitons is equal to the speed of light;
- black holes have a gravitational effect, and accordingly emit gravitons and lose energy. And as a result, they will disintegrate, since they will be unable to hold the particles included in their structure;
- the whole universe will eventually disintegrate into elementary particles.

### [Principle of equivalence of the forces of gravity and inertia (Einstein's Elevator)](http://howallworks.github.io/blog/2015/02/printsip-ekvivalentnosti-sil-gravitatsii-i-inertsii-lift-einshteina.html)

Date of initial publication in Russian: 24.02.2015

A description of the principle of equivalence of the forces of gravity and inertia can be found, for example, [in Wikipedia](https://en.wikipedia.org/wiki/Equivalence_principle).

This principle is incorrect, as it does not correspond to reality. Next, consider the rationale.

Gravity has the same effect on all parts of the object. For example, if a person is placed in the gravitational field of the Earth, then a stream of gravitons continuously passes through his body, acting uniformly on each part of the body. That is, a force is applied to each atom equal to the product of the mass of the atom by the acceleration of the free fall of the Earth ($g\sim 9.8\text{m/s}^2$). As a result, all parts of the body in the gravitational field move synchronously, and the body does not have any deformation loads.

The force of inertia acting on an object inside the elevator is equal in modulus and opposite in direction to the reaction force of the support during acceleration of the Einstein elevator. The acceleration of the elevator has different dynamic effects on different parts of the object. For example, if a person is placed in an elevator moving with significant acceleration (you can feel the effect in any elevator gaining speed) or, for example, when an airplane pilot performs aerobatics, then different effects are exerted on individual parts of the body. Consider the example of an elevator accelerating away from the surface of the Earth. The elevator begins to accelerate and shifts relative to the person in the elevator, which leads to an increase in the reaction force of the support on the soles of the person's shoes. The rest of the body is not yet affected by the acceleration of the elevator. Due to the increase in the reaction force of the support on the soles of the shoes, their deformation compression occurs, which in turn leads to an increase in pressure between the atoms of the sole of the shoes and leads to their acceleration relative to the rest of the body. Then the deformation is transmitted along the chain from the soles of the shoes to the ankles of the person, then to the shins, then to the hips, then to the pelvis, then to the spine, then to the internal organs and the head. I would like to emphasize that since the internal organs are not tightly fixed inside the body, they shift and deform when accelerated in an elevator or airplane (unlike the effect of gravity on them). And it is precisely because of this that a person is not able to withstand prolonged acceleration (overload) of more than 10g. As a result, different parts of the body move asynchronously and the body experiences dynamic deformation loads.

In fact, by deformation, it is possible to determine which of the forces acts on the object: the gravitational force or the force of inertia. Under the influence of the gravitational force, deformations will not be observed, and under the influence of the inertia force, dynamic deformation will be observed depending on the value of acceleration up to the destruction of the integrity of the object. At the same time, any value of a homogeneous gravitational field will not deform the object.

A good example of the absence of deformations is the International Space Station (ISS). Although the gravitational force is almost the same as on Earth (the acceleration of gravity is ~ 8.8 $m /s ^ 2$), but the ISS objects do not experience deformations.

What is the difference between the force of gravity and the reaction force of the support (equal in modulus and opposite in direction to the force of inertia during acceleration of the Einstein elevator) at the atomic level?

The force of gravity is, in fact, the influence of gravitons on all the atoms of an object. If the gravitational field is homogeneous, then the acceleration given to each atom is the same.

The reaction force of the support is, in fact, the influence of the support atoms exclusively on those atoms of the object that come into contact with the support atoms.

As a result, the principle of equivalence of the forces of gravity and inertia is incorrect.

#### Supplement (2015.12.19):

Let's take the formulation of the principle of equivalence of the forces of gravity and inertia directly by Einstein himself:

_"A little reflection will show that the law of the equality of the inertial and gravitational mass is equivalent to the assertion that the acceleration imparted to a body by a gravitational field is independent of the nature of the body. For Newton's equation of motion in a gravitational field, written out in full, it is:_

_(Inertial mass) * (Acceleration) = (Intensity of the gravitational field) * (Gravitational mass)._

_It is only_ **when there is numerical equality between the inertial and gravitational mass that the acceleration is independent of the nature of the body**_."_

What are the restrictions on the experiment here? It says here that the force of gravity and the force of inertia have the same effect on the object (with the equality of gravitational and inertial mass) and it is impossible to distinguish this effect.

Here is an experiment in which it is clearly determined which of the forces is acting:

The first case. A ship /"Einstein elevator", which is affected only by the force of gravity (for example, under the influence of a massive object). Acceleration is present, there is no reaction of the ship's support to the person in it, there is no deformation load between the atoms of the ship / person due to acceleration.

The second case. The ship /"Einstein elevator" (located at such a distance from a massive object that the force of gravity tends to zero), which is affected only by the force of inertia (for example, under the influence of the ship's engine). Acceleration is present, the reaction of the support of the ship to the person in it is present, the deformation load between the atoms of the ship / person due to acceleration is present.

It should be especially noted that the above experiment is correctly carried out according to the formulation of the equivalence principle (forces of gravity and inertia) of Einstein.

In fact, this experiment contradicts the Einstein equivalence principle, respectively, according to this experiment, the principle of equivalence of the forces of gravity and inertia of Einstein is incorrect.

### Active and passive masses 

Now based on the fact that everything in the world consists of $q.ph .^+$, $q.ph .^-$ and $q.g.$ need to discuss the concepts of mass.

The mass can be active and passive.
The active mass - how much $q.g.$ an object/system of elementary particles emits per unit of time.
Passive mass - how much $q.g.$ interacts with an object /system of elementary particles per unit of time when irradiated with a same/identical flow of $q.g.$

The active and passive masses strongly depend on the structure of the object, the speed of movement relative to the ImFR (immobile frame of reference). Let's see how the structure of the object affects. Let's take an electron plus a positron and compare it with a neutrino plus an antineutrino in the transformation:
$$e^+ e^- → ν \overline ν $$
Total amount of $q.ph .^+$, $q.ph .^-$ must be identical. Unfortunately, we cannot determine the amount of $q.g.$ yet. However, for an electron and a neutrino, the active and passive masses will differ due to structural differences. The neutrino has a lower active mass and, most likely, a lower passive mass, too, due to the higher density of the structure.

Based on [[theoryofeverything.en#Dependence of the period of processes in the object on the speed of movement of the object relative to ImFR|dependence of the period of processes in the object on the speed of movement of the object relative to ImFR]] one more conclusion can be drawn.  
When the speed of the object is higher, then lower the active mass (radiation $q.g.$) and the radiation of photons, too. Naturally, this will be strongly noticeable only at relativistic speeds (relative to ImFR).

### Space

The knowledge that humanity currently possesses allows us to confidently assert that the space of our world is three-dimensional and continuous (has no discreteness). The rationale for the continuity of space and time is described in the section  «[[theoryofeverything.en#Continuity of space and time|Continuity of space and time]]» .

To prove three-dimensionality, consider a simple thought experiment. Let's imagine a two–dimensional world with an infinite surface, and for even greater clarity - a sheet of paper. The three-dimensional world can be represented by an infinite set of infinite surfaces lying parallel to each other, and for a simplified representation – an infinite or even a finite stack of paper. If the world is three-dimensional, then objects of the three-dimensional world can eventually appear and disappear in two-dimensional out of nowhere and change their configuration. A good example can be obtained by pouring a bubble of ink on a stack of paper. At the initial moment, there were no ink particles in the two-dimensional world (on the sheet), but over time, ink particles appear out of nowhere and the spot begins to expand and penetrate into other two-dimensional worlds (on the sheets inside the stack). This example shows that if there is an object of a higher level of dimensionality (n+1-level) and it interacts with the lower world (n-level), then n+1-level objects from the point of view of the n-level are guaranteed to be observed (they are present in this world), and they appear in a fantastic way out of nowhere, they change inexplicably and disappear into nowhere. Due to the fact that this is not observed in our world, we can conclude based on the available knowledge that our world is three-dimensional.
Of course, you can say as much as you like that our World has a dimension greater than three, but based on the proved above it follows that our world does not interact with other three-dimensional parts of the assumed four-dimensional space, that is, returning to the example with a stack of paper, its sheets do not interact, and therefore there is no point in complicating the representation by adding the dimensions of space that do not relate to us (to our world).

### Fate and probability

The concept of the probability of an event is incorrect, and it is incorrect to use it, since our world obeys laws and, as a result, when the world laws are fulfilled, the consequences are unambiguous, and, consequently, everything in the world is predetermined and each object and the whole world has one path – fate (world laws => unambiguity => fate). In fact, the laws of the world are the rules of our world, and if they did not exist, the world would be in chaos (total disorder). For example, the position of particles and objects would be arbitrary over time, time would change arbitrarily, the same particles or objects would interact absolutely differently, it would be impossible to predict anything. The consequences of fulfilling the law are unambiguous, since by definition the law is a rule, and if it is executed, then the result of its execution is unambiguous.

The truth of the world can be comprehended exclusively experimentally (observation is a special case of experiment, and all other approaches are already an analysis of facts). All types of experiments show that when more precisely the conditions for conducting a series of experiments are set, then smaller the deviations of the results, and, consequently, if the conditions completely coincide (which is almost impossible to implement), there will be no deviations, which, in turn, indicates the mandatory implementation of world laws.

Probability is created to partially describe the behavior of objects and systems. Even at the quantum level, randomness "occurs" (artificially introduced) when we do not take something into calculation and try to at least partially describe the phenomenon under study.

It is impossible to change fate, because it is impossible to change the laws of the world.

It is impossible to change the laws of the world while inside the system, and if the change of laws is embedded in the system, then it is also a law.

Let's look at all this from a different point of view and try to prove the existence of randomness in the world. Suppose there is a "law" of randomness in the world, according to which random events occur. Let's figure out what this means. Based on this "law", the behavior, dynamics, characteristics, properties of elementary particles, interaction between elementary particles, features of space and time have an element of randomness, that is, they change in an arbitrary way. This means that in the same situation (complete coincidence of experimental conditions), any object (including an elementary particle) behaves differently. This can already be tested experimentally. This is not observed for macro objects (based on experiments and publicly available observations). For micro-objects (including elementary particles), the situation is such that it is currently impossible to recreate exactly the same conditions. However, when conducting any experiments, the following trend is obtained. The smaller the deviation of the conditions, the smaller the deviation of the results (characteristics, properties, dynamics, etc. of elementary particles or composite micro-objects and other characteristics of the world). Accordingly, this can mean only one thing – if all conditions are compliance, the experiments will give the same results, which means there is no "law" of randomness and the consequences are unambiguous, which leads to universal unambiguity – fate. There are many examples from the microcosm that indicate a decrease in the deviations of the results with a decrease in the deviations of the conditions:

- conservation laws;
- absorption/emission of photons by matter (only photons of a certain energy range are absorbed/emitted);
- identical orbits of electrons in atoms;
- identical transformations of high-energy particles in their collision;
- identical chemical reactions;
- the same depth of penetration of particles into the substance, etc.

In fact, any experiment is an example, but the trend will be more clearly visible on some, and less clearly on others. The reason for this is simple – how exactly the conditions are met. In reality, it even happens that only the most insignificant conditions are met, which leads to an almost complete absence of a trend.

It is worth noting that the sum of randomness does not give a regularity (law) in the sum. For example, let's imagine a group of particles that make up an object. We will assume that the particles move at a constant speed $v$. The velocity vectors will be directed absolutely randomly, which means that the case is possible when the sum of the velocity vectors is compensated and equal to 0, as well as the case when the velocity vectors have one direction and, accordingly, the sum of the velocity vectors is equal to $v$. Intermediate values from 0 to $v$ are also possible. In addition, any direction of the velocity vector is also possible. As a result, the speed of the body and its vector are absolutely random (the area of randomness is not reduced and occupies the entire spectrum allowed under the conditions). Which, in turn, confirms the statement that the sum of randomness is random and cannot be described by law, which is not observed in the world, which means that there is no randomness in the world.

All random variables are not random, since they have a law of their receive/the law of distribution of a random variable (for example, linear, exponential, normal, etc.).

### Heisenberg's uncertainty principle

Heisenberg's uncertainty indicates that at the current stage of the development of science and technology, it is not possible to simultaneously determine the coordinate and momentum of a quantum object, and not that the object will be in several states or its state does not obey laws and it is impossible to say in advance what it will be.

There is no uncertainty/ambiguity.

It is impossible to accurately measure the parameters of an object without affecting it.

### Particles

According to the logic [[Photon.en|photon]] is a composite particle, since it is proved that the photon energy is quantized. Therefore, it is logical to assume that it is a composite particle and accumulates energy with the accumulation of particles that make up its composition (a photon consists of a group [[Quantum photon.en|quantum photons]]). The photon changes its trajectory under the influence of gravity, and therefore has a passive mass.

Black holes emit gravity ([[Quantum graviton.en|quantum gravitons]]), and accordingly, they lose particles (quantum gravitons) and their energy, which means that they lose active mass ("evaporate"). The cause of radiation is the interaction of an elementary particle or a system of elementary particles between themselves and surrounding objects that either do not hold an elementary particle or a system of elementary particles well enough, or transmit a sufficiently large impulse (change the stable trajectory of an elementary particle or a system of elementary particles to an unstable one). The shielding of gravity in the representation of gravity in the form of particles is possible and logical (it has unconfirmed experimental evidence in the experiment with rotating superconducting plates – the Podkletnov effect).

The energy of an object is determined by the number of elementary particles that make up it and the direction of their velocity vector.

The speed of elementary particles is constant, the condition is necessary in order to comply with the rules of the world (for example, quantization of energy). For more information, see the section «[[theoryofeverything.en#Immutability of the speed of elementary particles|Immutability of the speed of elementary particles]]».

When considering all known types of interaction (gravitational, electromagnetic, strong and weak), the following should be noted. All the "transformations" of "elementary" particles of the Standard Model into each other are nothing more than the interaction and exchange of elementary particles - [[Quantum photon.en|quantum photons]] and [[Quantum graviton.en|quantum gravitons]].

### Matter

Matter is not a product of consciousness, since in the case of the opposite, it would be possible to change matter and its properties by the power of mind. In fact, consciousness is a product of matter.

Matter consists of elementary particles. There are no waves (an elementary particle has no wave properties), and fields are a combination of particles.

Interaction between objects (particles) occurs through the interaction of "interaction particles" with objects. For this reason, there is an interaction shielding effect.

The effects of interference and diffraction can be easily explained if we take into account the re-emission of particles by a "barrier" (particles of surfaces, slits, membranes, lenses, etc.).

The quantization of energy is also explained by the fact that matter consists of particles, the number of which is limited.

The laws for all "levels" of matter (microcosm, macrocosm, megaworld) are the same and follow from elementary particles and the laws of their interactions.

Energy is a characteristic of matter that does not exist without it.

### World

The world is a set of elementary particles, the laws of their interaction and the laws of its beginning and end. The position of the particles changes over time. The practical proof of all this is the whole world, the facts of which confirm this theory.

The inner, virtual world, the world of thoughts and ideas are "material" because they have material foundations – they are described by material processes in the brain or on a computer. Without the material activity of the brain and the storage of data about these worlds in the brain, they would not exist. Therefore, although they (objects of the world) may not exist in nature (outside of human), but they are "material", since they are described by the behavior of matter and stored in it.

### Knowability of the world

The world is fully knowable, that is, it is possible to determine the substances of matter and the principle (laws) of their interaction. However, it is not possible to fully predict the behavior of the world (it is impossible to predict the future), since for this it is necessary to store and process information about all particles (objects) of the world, and there will not be enough storage objects or computing power for this.

The world is fully knowable, since it is possible to determine all laws and elementary objects (particles /substances). If the behavior of a model based on these laws and elementary objects completely coincides with the behavior of a real system under the same conditions, then these laws and elementary objects (in the model) are the laws and elementary objects of the world.

### The beginning and the end of our world

The beginning of our world is the Big Bang without the superluminal inflation of space. The end of our world is a Big freeze and a Big scattering.

The Big Bang is the process of interaction between elementary particles of an ultra–high-density clot in an empty, potentially unlimited space.

Based on the available facts, it can be argued that our world is not cyclical, since at the moment there are no forces or, more precisely, elementary particles capable of collecting all the elementary particles of the world into an ultra-high-density clot.

Any world, including the primary one, has a beginning at the moment when elementary particles and laws and/or something else appear out of nowhere. And no matter how strange the appearance of something from nothing is, neither one world can exist (be formed) without it.

Big freezing is the process of reducing the concentration of elementary particles that are part of each system of elementary particles and on which their temperature depends. A decrease in the concentration of these particles occurs due to the inability of the system itself to retain them. In fact, if you put any system in an absolutely empty space, then all the thermo particles will quickly leave it and the remains of the system will have a temperature of absolute zero, which is actually partially observed in outer space when an object is placed there that is not illuminated by the Sun or other photon sources. In this case, the object does not reach the temperature of absolute zero due to the presence of a significant concentration of photons in modern outer space. Due to the fact that elementary particles can change their trajectory only when interacting with other elementary particles, some particles of the edge of the filled part of the universe have such a direction of movement that they will never interact with others. This leads to the fact that the particles of the universe increase the size occupied by them and, accordingly, their concentration decreases. This, in turn, leads to the process of Big freezing. In practice, the process of developing particle dynamics in our universe is largely similar to the process of an explosion in a vacuum or a rupture over the entire surface of a gas bottle in an empty, unlimited space.

Big scattering is the process of loss of stability of all systems of elementary particles, which eventually leads to the presence in the world of only isolated elementary particles that do not form linked systems. The issue of stability of elementary particle systems is considered in the section "[[theoryofeverything.en#Stability of elementary particle systems|Stability of elementary particle systems]]".
As a result, based on the available facts, we can conclude that Big scattering is the future of our world.

Infinity is a purely mathematical concept. In the world, everything is determined by physics, in which all quantities are finite. Some of these quantities are not limited in principle, but always have finite values. Let's get back to the main question. Even if our world was cyclical, it would still have a beginning. And the time of its existence is a finite quantity. In fact, any world, including the primary one, has a beginning at the moment when elementary particles and laws and/or something else appear out of nowhere. And no matter how strange the appearance of something from nothing is, no World can exist (be formed) without it. As a result, the appearance of an ultra-high-density clot of elementary particles from nothing, which subsequently led to the Big Bang, is either a trivial beginning of our world, or a specialized law that organizes the cyclicity of the world. Due to the fact that the second option is largely far–fetched, then, apparently, the Big Bang is the beginning of our world.

#### Time since the Big Bang

Theoretically, for some time the universe could be an ultra-high-density black hole that emitted only gravitons. What happened after that?

James Webb Space Telescope have been detected light from already a clearly formed isolated galaxy. We observe the light from it that has been travel to us for about 13.5 billion years. When the Universe was 2.3% its current age (about 13.8 billion years according to the Big Bang theory).
If space really expanded at superluminal speed at the beginning (after Big Bang), then the density would be uniform and extremely low. It would take a huge amount of time for galaxies to form, since the forces acting on the particles would be almost balanced. Or would there be only quantum photons and quantum gravitons at all, whose velocity vectors would be directed "randomly" without any dedicated direction.
Imagine a super elastic trampoline that has been stretched, for example, in billion billion billion times in every dimension. The trampoline particles will be at a large but approximately equal distance from each other. 
As a result, the time it will take for galaxies to form will be incomparably more than 13.8 billion years, not to mention 320 million years.

Assuming the most far-fetched case. The Big Bang begins. Then the particles of the outer edge are accelerated to speeds close to the speed of light due to the "pressure"/forces exerted by the inner layers of the ultra-high-density clot of particles (the velocity gradient from zero in the center of the clump of particles to the speed of light along the outer perimeter of the clot). Then there is a superluminal expansion of space. But even so, the final density would be uniform and extremely low. After that, the formation of galaxies would take even longer (than for the case with near-zero particle velocity). The particles of the outer edge would practically not interact with each other at speeds close to the speed of light, since their velocity vectors would not intersect. Which absolutely does not correspond to the observed data.

Suppose that our galaxy is moving at a speed about speed of light. But this is not the case, since there are no relativistic effects and the picture of the observed universe also does not correspond.

Everything can be explained with a long time of particle dynamics at speeds lower than the speed of light after Big Bang without the superluminal inflation of space.
The data also tells us that the farther a galaxy is from the center of the universe, the higher its speed. This is typical precisely for the explosion of an ultra-high-density clot in a vacuum. But it doesn't look like the dynamics of particles after the superluminal stretching of space at all (because total speed of movement of forming galaxies would be about zero and, as a result, would tend to the center of the universe. Or galaxies would have formed incomparably much longer than the specified time frame).

The time that has passed since the Big Bang without the superluminal inflation of space is summed. Time of the particles scattering, of forming and separating standalone galaxies - more than 13.5 billion years. And time for which light reaches us from the most distant galaxies is about 13.5 billion years. In total, more than 27 billion years.

### The Limitations of the world

The world is limited by the parameters, characteristics and properties of elementary particles, the laws of their interaction, as well as the laws of its origin. Accordingly, there are ultimate limits for all parameters, characteristics and properties of any objects.

### «The Matrix»

The existence of a "Matrix" – an illusory or unreal world (non–primary world) - is possible, and any "object" located in it will not be able to prove that it is a "Matrix" if there are no external influences and the "object" does not have information about the outside world. However, to organize such a "Matrix" will require more resources than it is service. It is worth noting that numerical modeling allows you to control only discrete quantities, but our world is continuous. Accordingly, the "Matrix" should directly control elementary particles and the laws of their interaction. Based on this, there is a guaranteed opportunity to determine the impact on our world from the outside. In principle, suppose it is possible to control particles from the outside or add/remove particles, but this will lead to a violation of laws, and, accordingly, can be tracked from the inside. If laws are enforced in the world, then in order to control it from the outside, it is necessary to make changes in these laws, which, in turn, can be discovered in our world. As a result, due to the fact that there are no proven facts of interference in laws, this excludes the possibility of controlling the world/human from the outside. In addition, there are no grounds (facts) to consider our world an illusion.

### System

The properties of the system are completely determined by the properties of its parts or particles. Although new properties appear in the system, they are completely determined by the properties of its parts, which means the properties of elementary particles. In fact, any system is "constructed" (consists of) elementary particles that obey the laws of the world, which means that any properties of the system are determined by these particles and laws. However, the number of elementary particles, their concentration, sequence, direction of movement and their other characteristics may be different. All this leads to the fact that if we consider systems at a higher level of representation (particles, atoms, molecules, macrobodies, etc.), then their properties can also be different, although they are also determined by elementary particles and laws. Nevertheless, the laws do not change, and the differences are defined precisely with the characteristics of elementary particles and their spatial location, that is, with the specificity of the "combination" of elementary particles.
As a result, it is the "combination" of elementary particles that determines the properties of the system. It is worth noting that the property of the system is, as a rule, an abstract (very simplified) representation of the properties of the "combination" of elementary particles and the laws of their interaction.

As a result, we can say that it is the creation and development of the science of the "combination" of elementary particles that can benefit. Moreover, when elementary particles, the laws of their interaction and their dynamics are better studied, then more accurately it will be possible to predict the behavior, characteristics and properties of any "combination" of elementary particles (systems). 

### Synergetics and general theory of systems

Synergetics in its current form is a pseudoscience, since in a world with fixed laws there cannot be branching and bifurcation (breaking points). Moreover, the properties and abilities of an object are completely determined by the properties and abilities of its parts. All systems are inherently open and change over time. The concepts of chaos and order are applicable only at a certain level of abstraction, but in reality everything is ordered.

On the other hand, the science of the general theory of systems has the right to life and development, since, although the system can be described at the level of elementary particles and modeling for comparison with the real one, the number of elements is so large that at the moment it is not possible to investigate large systems. To investigate large systems (systems consisting of a large number of elementary particles), it is necessary to neglect accuracy and, for example, construct a model from larger primitives. The key point is that there are no complex or simple systems, there are systems consisting of a relatively large or small number of elementary particles. The larger the number of elementary particles, the more difficult it is to accurately predict the behavior of the system. The complete prediction of behavior depends purely on the number of elementary particles entering the system. However, with the use of a certain level of abstraction (simplification), some characteristics can still be partially predicted for some even very large systems.

### Schrodinger's Cat

A thought experiment. The cat is locked in a steel chamber together with a radioactive substance, which, when decay, leads to the killing of the cat by a special mechanism. However, by the time the chamber is opened, the radioactive substance may not decay. This will lead the observer to see that the cat is alive. As a result, until the moment of direct inspection of the camera, the observer cannot tell whether the cat is alive or dead, and, accordingly, the cat is in two conditions at the same time: alive and dead. In fact, this leads to uncertainty of the cat's condition.

Probabilities exist only for a partial (simplified) description of complex systems. There are no probabilities in the real world, because laws are fulfilled in it, and probability can exist only if laws are not fulfilled.
There is a law – there is unambiguity.
As a result, we can initially tell whether the cat will be alive or dead at a particular time moment.
The nucleus of an atom apparently decays when a certain threshold of energy (the number and directions of motion of elementary particles) is exceeded / insufficient, that is, if we know the energy threshold, the initial amount of energy and the incoming/decreasing amount of energy, then we will be able to say unequivocally when the nucleus will decay.

### No-cloning theorem

The [theorem](https://en.wikipedia.org/wiki/No-cloning_theorem) consists in the statement of quantum theory that it is impossible to create an ideal copy of an arbitrary unknown quantum state, which has a mathematical proof.

The theorem is relevant only with the current development of science and technology, but there is no restriction in the world on creating a perfect copy (although it is very difficult to put everything together piece by piece and set the correct initial state).

The whole point is that the physical measurement of the state of the system inevitably leads to a change in its state. This is a fact. However, this transition is always reversible, that is, the system can be returned to its original state or any required by a series of special actions.

In fact, in order to physically measure the states of the elementary particles of the system, it is necessary to interact with a number of elementary particles, according to the initial and final state of which it is possible to determine the corresponding desired states of the elementary particles of the system. After that, it is necessary to amend the intervention in the system by means of the influence of a number of elementary particles with the necessary states. As a result, researchers will have the initial system and knowledge about the states of all elementary particles in its composition, and, consequently, it is possible to synthesize its ideal copies.

The only problem in this case is the accuracy of creating a copy, which is a technical problem, not a physical one.

Most likely, with the development of science and technology, cloning and, accordingly, teleportation will become possible.

### Over-barrier reflection

Over–barrier reflection is the reflection of a particle from a potential barrier whose height is less than the total energy of the particle. This phenomenon is impossible from the point of view of classical physics.

The reason for this effect is not the probability or wave properties, but the banal interaction between particles and /or measurement inaccuracy, that is, some of the particles that overcome the barrier will have different energy, but more than the barrier and on average more than the average energy, and the particles that do not overcome the barrier have energy less than the barrier (part of the energy they rely on energy was transferred to other particles). The same thing happens with body temperature. The temperature of the body parts (in the extreme case of elementary parts) will differ from the average body temperature. The effect of particle tunneling is similarly explained. It is also worth noting that the barrier or tunnel itself is not physically a clear boundary in spatial coordinates and, moreover, changes over time.

### The Quantum Zeno Effect

[The Quantum Zeno Effect](https://en.wikipedia.org/wiki/Quantum_Zeno_effect) (Zeno's Quantum Paradox) — the paradox of quantum mechanics, which consists in the fact that the decay time of a metastable quantum state of a system with a discrete energy spectrum directly depends on the frequency of events measuring its state. In the extreme case, an unstable particle under conditions of frequent observation of it can never decay.

The effect is easily explained when viewed energetically or from the point of view of elementary particles. During observation, we transfer/take away the missing/excess energy (more precisely, elementary particles) to the system, the lack /excess of which could destroy it. Without observation, naturally in the process of dynamics, the system gradually emits/absorbs elementary particles, which leads to its destruction.

### Parallel worlds

There are no parallel worlds that are generated by the branching of the world as a result of the choice of various alternatives, since there are no alternatives due to fate (the immutability of universal laws).

There may be parallel worlds independent of ours, but it is impossible to prove their existence, since the worlds do not intersect.

### Gravity

Gravitational interaction is one of the most important processes occurring between objects of our world. Next, let's look at how the gravitational interaction is carried out.

There are several options for the implementation of gravitational interaction. Suppose that all "elementary" particles are connected by special elementary particles, which are responsible for gravity. Then there is a gravitational connection between each pair of "elementary" particles. As a result, we get a fully connected web. This explains the reason for the presence in the numerator of the multiplication of masses of a pair bodies in the formula of the law of universal gravitation ($F=G \frac{M_1M_2}{R^2}$). However, in this case, it is very difficult to explain the reason for the presence of the square of the distance in the denominator of the formula, since with this representation, the graviton connecting the "elementary" particles will run between them like, for example, a train between cities. Hence we get that the denominator of the formula should be the distance, not its square. This is not observed experimentally, which means that such an assumption is incorrect. It is worth noting that the considered option cannot be completely excluded, since the possible presence of the square of the distance in the denominator of the formula may be due, for example, to the intensity of the gravitonic interaction and/or the conditions of "radiation" of gravitons between "elementary" particles and/or something else.

Now suppose that an "elementary" particle constantly "radiates" gravitons in all directions of three-dimensional space. Then the square of the distance in the formula ($F=G \frac{M_1M_2}{R^2}$) will be justified, since the density of gravitons will decrease in proportion to the area of the sphere and, accordingly, in proportion to the square of the distance. Next, it is necessary to deal with the masses of bodies. The mass of the body "emitting" gravitons, in fact, determines the number of gravitons emitted, which justifies its presence in the numerator of the formula. Now it may seem that then the mass of the second body has nothing to do with it, but do not forget about the need to "absorb" gravitons. The mass of the "absorbing" body is responsible for the "absorption". However, it should be noted that this is possible and realistic with a weak "absorption" of gravitons by matter, for example, due to the small radius of interaction with elementary particles. This description of gravity agrees well with experimental data, and, accordingly, this means that it is close to reality. However, it is worth noting that such a description leads to one important consequence. Due to the fact that not all gravitons are eventually absorbed by "elementary" particles, for example at the edge of the universe, some of them fly away into space without "elementary" particles, which means they will never be able to return to the system of elementary particles. This will eventually lead to the "depletion" of the links between elementary particles, that is, to the scattering of gravitons.

If we assume that gravitons are generated out of nowhere, then this will lead to gravitational stability, but it will violate many, and maybe all existing laws, for example, conservation laws, which is not observed experimentally.

### Immutability of the speed of elementary particles

All interacting elementary particles, that is, absolutely all elementary particles of the world, have one speed - the speed of light.

The speed of elementary particles is constant, since at variable speed the effects of these particles on anything would be different. What is not observed in the world.

Based on the available experimental facts, all elementary particles move at a constant speed, and the speed of objects (combinations of elementary particles) does not coincide with the speed of the particles that make up it, due to the "chaotic" motion of elementary particles (velocity vectors have different directions and there is no priority direction). For example, each elementary particle has a speed $v$, but the direction of their motion vectors is "chaotic", then with a large number of elementary particles, the modulus of the vector sum of speed "tends" to zero. Also, if the vectors of some direction prevail, the object has a velocity vector of the same direction. Accordingly, if the velocity vectors of all elementary particles are equally directed, then the speed of the object will be equal to $v$.

Different (variable) speeds of elementary particles would lead to different properties, characteristics and behavior of composite particles (the behavior of systems would be different) within very wide limits. In fact, composite particles (particle systems) in this case could be considered with certainty as different particles (particle systems) with unique properties and behavior. This would lead to the inability to even partially predict the behavior without having all the knowledge about all the particles that make up such a system. It would also lead to a total lack of classification, and since the composition and speed of the elementary particles that make up the system (object) would change over time, its properties and behavior would change. It is especially important to note that quantum effects (for example, quantization of energy) are possible only if the speed of elementary particles is constant. In addition, the constancy of the speed of elementary particles is indicated by carriers of electromagnetic and gravitational interactions, that is, photons and gravitons.

Imagine a pair of atoms with the same composition, but different speed of all the elementary particles that make up them. Their behavior and characteristics will be radically different. For example, the red border of the photo effect would be different for them, and besides, it would change over time. It is worth noting that in reality the behavior and characteristics of atoms are almost identical, and the differences are due to differences in the composition and phases of mutual rotation of systems of elementary particles.

If elementary particles had variable speed, then their energy spectrum would be continuous and would have the ability to take a zero value at zero speed, which, based on the facts, does not correspond to reality.

With the variable speed of all elementary particles, all the properties and characteristics of elementary particle systems, even with the same composition, could be radically different and dynamically change over time, which does not correspond to reality.

It is worth noting that there are no experimental facts about the "disappearance" and "appearance" of elementary particles of the world, and, consequently, scattering, absorption, radiation, etc. are nothing more than a change in the composition of the system of elementary particles, and not a mystical "transformation" of an "elementary" particle.

The assumption of complex geometry and dynamic changes in the structure of an "elementary" particle (for example, atoms, protons, electrons) does not correspond to reality due to the facts of "transformation"/restructuring of particles into other particles. This means that the irradiated "elementary" particle is not an elementary one, but a system of elementary particles, each of which moves at a significant speed. This is also indicated, for example, by the absorption of photons by an electron, which are part of its composition. In fact , an electron consists of $q.ph .^-$ and $q.g.$, and the positron of $q.ph .^+$ and $q.g.$.

During the annihilation of an electron and a positron, "often" (at certain energies), only a few photons are obtained (released, scattered), according to current data, which indicates the absence of particles with variable speed in the composition of the electron and positron. In fact, it seems that [[Quantum graviton.en|quantum gravitons]] are also distinguished during annihilation.

There are no experimental facts of finding "non-transformation" elementary particles (really elementary) with variable speed.

At different speeds of elementary particles, the result would be this – legitimate chaos, that is, although the laws and particles are the same, but the behavior of everything in the world is unstable and unpredictable in time at practice.

As a result, we get that all elementary particles have the same and constant speed.

In fact, based on the same particle speed, one can draw a preliminary conclusion about their elementary nature. However, it is possible that a system of elementary particles may have a common direction (vector) and the same speed, but it is still a system. In addition, it is possible that such a system includes elementary particles that bind it together ("link" particles), which are in a neutral state (compensation of attraction and repulsion) and have an effect only when acting on the system. At the same time, the particles of the "link" must have a speed greater (logically much greater) than the speed of the system, which is hardly possible, since the speed of all elementary particles is the same - the speed of light. The photon is not elementary, since its energy is quantized.

It is important to note that a global analysis of the "transformations" of particle systems can make it possible to better understand what elementary particles the world consists of. In fact, this analysis can make it possible to identify elementary particles, and not their systems, most of which are currently considered "elementary".

As a result, all conversions/"transformations" of particles indicate that everything in the universe consists of two types of elementary particles - [[Quantum photon.en|quantum photons]] and [[Quantum graviton.en|quantum gravitons]].

### Continuity of space and time

Suppose that space is quantized and time is continuous. Then a specific particle or its specific point is located at a certain quantum point in space. When the time changes by a small amount tending to zero, at any speed of the particle, it will change its coordinates to extremely small quantities also tending to zero, and, accordingly, the particle will remain at the same quantum dot. Due to the fact that the particle is located at this particular quantum point, through any number of time changes by a small amount tending to zero, the particle will also remain at this particular quantum point, which does not correspond to reality.

Assume that space is continuous and time is quantized. In this case, objects or elementary particles will interact differently each time. For example, the force of interaction between a pair of electrons in an absolutely identical situation, with the exclusion of the initial time quantization mark, will be different, and the pulses will also be different in each individual situation from a number of identical situations. This will happen due to the fact that the distances between the electrons when quantizing the time serifs will be different for each individual case. As a result, the positions, total forces, impulses or energy transfer of interaction for any objects or particles will be different, and therefore, for example, the law of energy quantization will not be fulfilled and interacting elementary particles flying along intersecting trajectories will sometimes pass through each other, which, according to the available facts, contradicts reality.

Now consider the case of quantization of space and time. In this case, a specific particle or its specific point is located at a certain quantum point in space (Figure 6), and in addition, time has discrete values at certain intervals.

![[pic5.png ]]

**Figure 6 – An elementary particle or a specific point belonging to it in a quantized space**

If the speed of elementary particles vary in a certain interval, then in the same time step they will travel different distances and almost all will not fall into quantum dots. In this case, even if we assume that each elementary particle will be in the quantum point of space closest to it, then there will be a lot of rounding errors that will be considered later. If we assume that the speed of elementary particles is constant, then if the velocity vector of the particle coincides with the x axis, the system will function correctly, however, if there is an angle α, the particle will not reach a single quantum dot or, with a large value of dt, it will almost always not fall into a specific quantum dot. This again leads to the fact that each elementary particle will be in the quantum point of space closest to it and, accordingly, rounding errors.

Let's look at rounding errors in more detail. If an elementary particle can only be in the quantum dots of space (according to the quantization of space), then at small angles α, the elementary particle will move purely along the x axis, since each subsequent quantum dot is no different from the previous one (Figure 7). We get that the vector of motion of any elementary particle in space is limited to a certain finite set of directions, which is not in reality. As a result, we will call this error – the error of a limited set of angles.

![[pic6.png ]]

**Figure 7 – Interaction of elementary particles in quantized space**

It is particularly worth noting that in the case presented in Figure 7 (at small angles α and β), either a "frontal" collision of elementary particles will occur, or elementary particles will pass through each other, which does not correspond to real facts. Moreover, with the discreteness of space and time, all the results of the interaction of elementary particles at different but small angles α and β will be exactly the same, which does not correspond to the observed facts.

When passing the direction of flight of an elementary particle through a quantum dot of space, but not hitting it in a time step, another rounding error occurs, namely, the error of violating the constancy of the speed of an elementary particle, since it is necessary to either accelerate or slow down the elementary particle to accurately hit the quantum dot. Accordingly, in this case, not only the laws of conservation of momentum and energy are violated, but in general the sequence of interaction between elementary particles can be changed. This leads to a violation of the laws of interaction and their various consequences depending on the directions of the vectors of elementary particles, which does not correspond to the available scientific facts.

As a result, the error of a limited set of angles in practice leads to the discretization of the directions of the vectors of elementary particles, which is easiest to observe, for example, when studying radiation from distant stars and galaxies, which is not in reality, and therefore there is no discretization of space and time. In addition, rounding errors lead to the loss or acquisition of the energy of an elementary particle or a system of particles, which leads, for example, to a violation of the law of conservation of energy in the interaction of any pair of elementary particles or to the lack of stability of the rotation trajectories of any systems of elementary particles, such as atoms, planets, stars and galaxies, which does not correspond to reality.

As a result, based on the available facts, it can be argued that space and time in our world are continuous (not discrete).

### "Wave" properties of "elementary" particles

The "wave" properties of "elementary" particles can be explained by representing particles purely in the form of corpuscles. The experimental basis of "wave" effects is based on the phenomena of interference, diffraction and polarization. First, it is worth noting that the photon, electron and other "elementary" particles of the Standard Model are not really elementary. For this reason, for example, the photon energy is quantized.

Imagine a photon in the form of a flat "plate" (a system of particles representing a very flat disk in total), then the phenomenon of light polarization will become clear and very simple. In fact, with the parallelism of the "plates" and the atomic crystal structure of matter, the main part of the "plates" freely slips through the polaroid, and the remaining part still "bumps" into the atomic structure. And if you put a second polaroid with a perpendicular direction of the atomic structure, then, of course, the "plates" of photons will hit the atomic structure and will not pass the second polaroid.

In addition, it can be said that photons of different energies (with different numbers of elementary particles included in their composition) differ in the radius of the "plate", which leads to the fact that photons of different energies ("wavelength" or "frequency") behave differently. Photons with higher energy (a large number of elementary particles in the composition), apparently, have a smaller radius of the "plate", which means they are easier to overcome obstacles. And for this reason, the same size of an obstacle or slit affects different "plates" of photons in different ways.

Interference and diffraction of light – redistribution of photon beam intensity in space after interaction with obstacle(s) or slit(s), as well as with discrete (quantum, not continuous) the structure of matter and photon. A dark dot or stripe indicates not the "superposition" of waves, but the absence of photons in this area. If the "waves" were superimposed, then an experiment would be possible to neutralize each other with two light beams, which is not the case in practice. The nonlinearity of geometry is related to the properties and structure of photons and obstacles.

Interference and diffraction of other particles are similar.

Waves and interference of "macro–objects" - liquids, solids and gasses are associated with changes and superimposition of their densities and, accordingly, pressures.

Consider an experiment to obtain Newton's rings in slits of small thickness (a lens is a flat plate).

Newton's rings are interference fringes of equal thickness in the form of rings arranged concentrically around the point of contact of two spherical surfaces or a plane and a sphere. First described in 1675 by Newton. Light interference occurs in a thin gap (usually air) separating the contacting surfaces. This gap plays the role of a thin film. Newton's rings are observed in both transmitted and reflected light. When illuminated with monochromatic light of wavelength λ, Newton's rings are alternating dark and light bands.

We get an interference pattern in reflected and transmitted light, however, when these pictures are superimposed, we get a picture with the same intensity. It is particularly worth noting that there is no drop in intensity in such experiments, which means that photons do not compensate for each other, as suggested by the wave addition formulas, but are redistributed in space. Accordingly, the wave interference formulas do not reflect the physics of the process.

### Stability of elementary particle systems

The stability of the elementary particle system is the absence of spontaneous (not forced) decay of the elementary particle system.

Consider what happens if all systems are unstable. Unstable systems of elementary particles eventually decay into elementary particles. The arguments are for this - the radiation of stars, black holes, namely, the emission of gravitons, photons, atoms and other systems of elementary particles by macrobodies. Imaginary stability arises due to the presence of a significant reserve of elementary particles and/or replenishment by surrounding elementary particles.

Now let's consider what will happen if stable systems exist. Stable systems do not emit anything. The arguments for this are the stability of a photon, perhaps a proton, an atom, or even a macrobody. Instability occurs due to direct interaction with the surrounding systems of elementary particles or individual elementary particles.

The information received from other star systems and galaxies is most useful in this case. The photons recorded in the radiation coming from them do not indicate the stability of the systems. Outer space is filled with many particles, such as photons, gravitons, etc., which possibly stabilize the states of elementary particle systems.

Interactions in any system of elementary particles are carried out by means of the same elementary particles. This means that for the stability of the system, it is necessary to have elementary particles – "couriers", each of which runs between elementary particles, carrying out interaction. At the same time, the "courier" should never leave this system (in the absence of impacts on the system) and thereby disrupt stability. Due to the fact that all elementary particles move at certain constant speeds, the "courier" must knowingly determine the trajectory of an elementary particle and fly to intercept it, which is very far-fetched and, accordingly, hardly possible.

#### Stable systems do not emit anything. 

All objects of the universe (which having mass) generate gravitational radiation, spend energy on it and exert a force effect on surrounding objects (details in section «[[theoryofeverything.en#Irregularity of gravity. Quantum graviton. Blazar - SMBH with relativistic jets|Irregularity of gravity. Quantum graviton. Blazar - SMBH with relativistic jets]]»)

Let's take all the particles of the Standard Model, except the photon and, possibly, the gluon. All of them emit [[Quantum graviton.en|quantum gravitons]], that is, they have an active mass. Consequently, they are unstable, since the reserve of [[Quantum graviton.en|quantum gravitons]] is limited in an isolated environment or in the long term during the spread of matter/antimatter in the universe.

A photon is actually a group of [[Quantum photon.en|quantum photons]]. And there is nothing to indicate that some other elementary particle is included in this group in order to move as a system of elementary particles. Moreover, [[Photon.en|photons]] do not interact with each other. If there was an additional elementary particle, it would interact with the quantum photons of its own and other photons, which would manifest itself in the interaction of different photons. Accordingly, again we come to the fact that the photon is a group [[Quantum photon.en|quantum photons]].

A gluon is extremely similar to a photon. Perhaps a gluon and a photon are the same thing. No free gluons were detected. The gluon is spoken about by indirect signs, namely by a jet of hadrons formed "from it". For example, the first direct experimental proof of the existence of gluons is believed to have been obtained in 1979, when experiments at the PETRA electron-positron collider at the DESY Research Center (Hamburg, Germany) revealed events with three hadron jets, two of which were generated by quarks and the third by a gluon. However, why is the source of the third jet a gluon and not a photon? I don't understand.

It is particularly worth noting that hadrons can form only in the presence of quantum photons and quantum gravitons. This indicates that there were enough quantum gravitons during the formation of the hadron jet. Neither a photon nor a hypothetical gluon contain quantum gravitons.

Apparently, in the experiment, the photon interacted with a large group of quantum gravitons and was transformed into a hadron jet.

As a result, there is no stability of elementary particle systems.

### What does the violation of Bell's inequality actually indicate

Bell in his theorem compares a certain "classical" interpretation of particles with the interpretation of quantum mechanics. And concludes that the "classical" interpretation does not correspond to the experimental results. Which I generally agree with regarding the violation of Bell's inequality. Why was the "classical" interpretation wrong? Firstly, because, as explained earlier, the particles of the Standard Model are not elementary and consist of quantum photons and quantum gravitons. Secondly, the "classical" interpretation of spin does not correspond to reality, if only because the studied particles are not elementary and consist of clusters of elementary particles with little-understood structure and dynamics. Thirdly, a photon is not a single particle, but a group of quantum photons forming a shape similar to the shape of a disk. Fourth, polarizers, slits, lenses and other barriers re-emit photons or other particles passing through them, and accordingly their trajectories change, the spatial orientation of the elementary particles (quantum photons and quantum gravitons) of which they consist (affects, for example, the polarization of photons, spin and other characteristics).

On the other hand, the conclusions of quantum mechanics about the nonlocality and probabilistic nature of the universe do not follow from the incorrectness of the "classical" interpretation. Such conclusions are simply a misunderstanding of what is happening in reality.

As a result, it is important to understand that the experimental violation of Bell's inequality indicates to us exclusively that the "classical" interpretation of particles is incorrect.

In fact, a proton is a clot of $q.ph .^+$ (quantum photon with positive helicity), $q.ph.^-$ (quantum photon with negative helicity) and $q.g.$ (quantum graviton), which has a neutrally charged residue on average will produce an equal amount of $q.ph .^+$ and $q.ph .^-$, and there is also a positive charged excess containing $q.ph .^+$ and $q.g.$. What, then, do we measure as its "spin"? Does it make sense in this case to talk about the projections of the "spin" in some direction?

[[Photon.en|Photon]] generally consists exclusively of a group $q.ph .^+$, or exclusively from the group $q.ph .^-$. The passage of a polarizer is also an effect on a photon (a group of quantum photons) and re-emission, which in fact takes place for the entire vacuum-free space.

It should also be well understood that particles whose spin is considered zero (for example, π-mesons and the Higgs boson) actually have an internal structure and consist of $q.ph .^+$, $q.ph .^-$ and $q.g.$.

The Stern-Gerlach experiment shows that particles with a spatial charge structure can be affected by an inhomogeneous magnetic field (for example, by a Stern-Gerlach device) and because of this their spin will not be considered zero. I would like to emphasize that it is the impact that gives the resulting experimental picture, and not a mythical probability.
It is important to understand that physically the impact of an electric and magnetic field is, in fact, the impact of photons with a predominance of positive or negative helicity. Accordingly, spin shows how the internal spatial charge structure of the particle reacts to the external impact with photons with a predominance $q.ph .^+$ or $q.ph .^-$. This again indicates that many even electron-neutral particles, which were considered elementary, have a structure containing zones with different charges, that is, consisting of quantum photons with different helicity. In fact, they consist of clots $q.ph .^+$, $q.g.$ and clots $q.ph .^-$, $q.g.$. The shape of the clots is currently unclear, since it is extremely difficult to obtain experimental data at the level of the internal structure of the particles of the Standard Model. We get that the modern term spin is a very strong simplification that poorly reflects the real dynamics of the internal structure of particles. Moreover, in the term spin, there is no clear understanding at all that the reason for the behavior of different particles is that they contain clots with different charges (different helicities of quantum photons). It is the clots of quantum photons with different charges/different helicity (some clots contain exclusively $q.ph .^+$, $q.g.$, and other clots contain exclusively $q.ph .^-$, $q.g.$) determine different spin behavior of particles.

Once again, I note that spin reflects not just the rotational features of the particle, but the charge dynamics inside the particle.

Let's move on to polarizing photon filters. If you put two polarizing filters at an angle of ninety degrees, it is assumed that the light does not pass because the first one blocks one direction of the wave, and the second one is perpendicular, that is, everything else. And because of this, photons do not pass. If we take three filters $0^o$, $45^o$, $90^o$, then the light partially passes. Why? The point is the wrong interpretation of the photon and the mechanism of action of the polarizer.

What's going on? The first filter blocks part of the photons, that is, part of them hits the atomic structure of the filter and is absorbed or reflected back, and the other part passes on. If you imagine a photon in the form of a disk, and a polarizer in the form of slots, then it becomes clear which disks pass and which do not. What happens next? If there is a $90^o$ filter, then all the remaining disks simply hit the atomic structure of the filter and are absorbed or reflected back. However, if the second filter is set to $45^o$, then part of the photon disks can simply pass without interacting with the atomic structure of the filter, part will collide and be absorbed /reflected, and part will collide and be re-emitted by the atoms of the filter structure further along the course of the initial movement of photons. It is this last part that is interesting to us. We have already observed the same thing when describing the processes of re-emission during interference/diffraction of light, for example, in an experiment with a pair of slits or in Newton's rings. It is the re-emission that changes the orientation of the plane of the photonic disks and allows part of them to pass through the third filter by $90^o$. This leads to the fact that as a result, part of the photons passes through all three filters $0^o$, $45^o$, $90^o$.

The most interesting thing is that in quantum mechanics and in the results of experiments, it is emphasized that photons that have passed through the second filter seem to "not know" that they passed through the first filter, that is, when passing between the second and third filters, they behave as if they did not pass through the first filter.

All this indicates that, in fact, all photons that have passed through the filter are re-emitted and change the orientation of the plane of the photonic disks. 
The distribution of orientations of photonic disks after passing each polarizer is not linear and will be proportional to $cos^2(x)$ when photons pass between neighboring polarizers, where $x ≤ 90^o$ is the angle between the main axes of a pair of neighboring linear polarizers. Then all the results will coincide with the experimental ones. It turns out that the smaller the angle between a pair of polarizers, the fewer photonic disks will be reflected by the last polarizer. We get that through a dozen polarizers deflected at small angles, much more photons will pass than through a pair deflected at a large angle. This is observed experimentally.

As a result, the whole thing lies in the structure of a photon (a group of quantum photons) in the form of a disk and in specific of the re-emission of photons by each polarizer.

Let's return to the violation of Bell's inequality. As we can see, the violation of inequality can easily be explained without waves, probabilities, lack of realism and lack of locality. Just when photons are represented by a group of quantum photons in the form of a disk, as well as a polarizer, which, when photons pass through it, re-emits them. 

Interference, diffraction, and polarization are also easily explained by the peculiarity of the re-emission of particles by barriers as previously explained.

### Quantum graviton versus space-time deformation of Einstein's general theory of relativity

This is a generalizing section of heterogeneous data, experiments, observations and conclusions described earlier, as well as the addition of new ones.

All impacts in our universe are carried by particles. At least this is the easiest way to describe the dynamics of our universe and it turns out an excellent agreement with real observations / experiments. Then why is the gravitational effect special? Can't gravity also be described by particles?

It is possible to describe by quantum gravitons. And at the same time, a much better correspondence to reality is obtained.

Why are objects of low mass, such as atoms and smaller ones, able to hold photons inside themselves like black holes? From the point of view of general relativity, this does not work well, since the deformation of space-time in this case is either too small, or should absorb everything that comes across as micro black holes. But this is not happening.
However, if we describe the atom and other particles in the form of clusters of quantum photons and quantum gravitons, then everything works correctly. This not only makes it possible to understand the cause of the emissions of both gravitons and photons, but also makes it possible to understand the mystical transformations of all the particles of the Standard Model into each other. It also indicates the incompleteness of the Standard Model due to the absence of gravitons in it, although almost all of its particles have an active mass.

Earlier in the section "General theory of relativity vs gravitational maneuvers and black holes" gravity maneuvers were considered. It turns out that for all real cases when there are several massive bodies moving relative to each other (due to which a gravitational maneuver is performed), the object inevitably acquires /loses speed and, consequently, energy relative to any of the massive bodies. Which does not correspond to the concept of the absence of force in [[GTR.en|GTR]].

However, in this case, the concept of quantum gravitons works fine again, since there is a force effect on the object and the transfer of momentum/energy to it. Although, in fact, there is a transfer of particles - quantum gravitons, followed by absorption and re-emission.

But then why don't we notice that objects/atoms/particles emit quantum gravitons and there are fewer of them inside? It's just that there are a lot of them and the radiated amount is extremely small compared to the available reserves. In addition, there are almost always external sources that constantly replenish reserves. All surrounding objects emitting quantum gravitons somehow make up for the shortcomings in the neighboring ones. But then comes the right thought. But what about the edge of galaxies or, even more so, the edge of the universe? Indeed, what radiates from the outer edge of the universe and will no longer interact with other particles will be lost forever.

Now we can better understand the reason for the decay of unstable particles/atoms. They simply lack quantum photons and quantum gravitons to maintain stability. It is also clear why they do not decay all at once, since there is a temporary replenishment of quantum photons and quantum gravitons from those that have just decayed. In this regard, quantum gravitons again describe reality better than GTR. This also indicates that when the particles/atoms that are currently unstable disintegrate, it will be the turn of the particles/atoms that now have imaginary stability due to replenishment from external sources to disintegrate.

Let's move on to the data from [[LIGO.en|LIGO]]. There was a slight change in mass (about 3 times the mass of the Sun) at a colossal distance of 1.3 billion light years and we were able to record this considering the fact that this effect was significantly greater than the level of other gravitational noise. What does this mean? From the point of view of GTR, this is a very small change in mass at a colossal distance. Moreover, the effect of this event decreases proportionally to the square of the distance. In addition, at distances many powers of magnitude smaller than this, significant events also constantly occur with a large change in masses. Why did we manage to record such a distant event with a small change in mass? GTR can't explain it correctly. However, if we imagine gravity in the form of quantum gravitons, then everything falls into place. The change in mass is not as important as the change in the number of quantum gravitons emitted during this event in a very short period of time (~0.2 seconds). Imagine our Sun. It has been emitting quantum gravitons for billions of years, holding our entire Solar system. Now imagine what happens if it emits them all in 0.2 seconds. A colossal gravitational explosion. It is because of such a colossal change in the gravitational flow that we were able to record such a distant event.

[[Blazar.en|Blazars]] - supermassive black holes emitting relativistic jets of particles is another important argument in favor of quantum gravitons. The mass of the blazar practically does not change and, accordingly, from the point of view of GTR, the deformation of space-time should be stable and have the same amount of curvature in all directions from it. Which does not allow us to understand how particles can fly away from the blazar at relativistic speeds.

However, everything falls into place in the case of the representation of the gravitational radiation of the blazar by an uneven flow of quantum gravitons. The maximum of the radiation is quantum gravitons in the plane of the galaxy, and the minimum is perpendicular to it. It turns out that the radiation in the minimum is so small that part of the matter from [[SMBH.en|SMBH]] flies out and forms jets (relativistic jets) of the blazar.
Why is there such an uneven emission of quantum gravitons for some SMBH? Apparently the whole point is in the rotation of the SMBH around its own axis at relativistic speeds.

This also explains why we can't find hypothetical dark matter. SMBH in the centers of galaxies emit quantum gravitons mainly in the plane of the galaxy and because of this, the density of gravitons does not fall as fast as the distance from the source increases. This turns out to be enough to keep the galaxy in the desired configuration without introducing additional masses. Additional details are also given in the section "Irregularity of gravity. Quantum graviton. Blazar - SMBH with relativistic jets"

As a result, the representation of gravity in the form of particles - quantum gravitons best corresponds to reality and perfectly complements the general unified concept of the theory of everything.

## Self-knowledge

### Consciousness and «I»

A person has consciousness in order to predict the consequences of certain actions and optimize interactions with the surrounding world (at least try).

Consciousness is a special brain optimizer for organizing interactions with the surrounding world, whose task is a selective but qualitative analysis of available and incoming information in order to predict the consequences of various actions. The result of the work of consciousness is the choice of an action option that will bring the best consequences in terms of taking into consideration various criteria – pleasures (pleasure theory).

Unconscious actions - actions performed without control of consciousness, that is, automatic actions inherent in a person, or actions brought to automatism, for which control of consciousness is usually not required.

The problem with performing unconscious actions is that in some situations, control of consciousness is necessary, without which the consequences of this action are worse.

"I" is the totality of the conscious and unconscious parts of a person.

Truly rational – based on true facts, knowledge, logic, absolutely based on reality.

Truly irrational – based on truly incorrect "facts", beliefs, absolutely unrelated to reality.

Actions performed consciously can be rational to varying degrees. A person performs irrational acts, since his knowledge and beliefs necessary to predict the consequences are erroneous, that is, they are built on incorrect "facts" that are not related to reality, but even in this case their goal is pleasure. For example, skydiving, driving at high speed, flying into space, robbery, arson, etc. although they have a significant risk to health, but as a result they bring pleasure, which a person strives to obtain. However, not everyone strives to perform certain rational or irrational actions, since their consciousness assesses the risks and considers them unacceptable.

All animals (including humans) have consciousness.

Self-consciousness evaluates the physical data of itself for the same purpose as consciousness. In fact, self-consciousness evaluates its physical characteristics to optimize interactions with the surrounding world, and the goal is to get pleasure. Self-consciousness should not be intentionally isolated into a separate structure, since it is part of consciousness.

### Human

A person is a set of elementary particles that obey the laws of the world.

A person is artificially (no in reality) assigned uniqueness and superiority over other objects / particles / systems (a set of particles considered together) in order to elevate him above the world and justify his existence and the meaning of life. In fact, a person is "identical" to a stone, since he is simply a set of elementary particles. In fact, by copying a person at the level of elementary particles, we will get an ideal copy of him, but over time the decisions made by the copy will differ more and more from the original in the same situations, since their perceptions (perceived information) differ, and accordingly knowledge will become more and more different.

### Human personality

The particles of the world obey its laws, therefore, everything is predetermined and cannot change at its discretion, and cannot come from nowhere. To be precise, everything in the world is predetermined by particles and the laws of their interaction. As a result, the concept of personality is determined solely by the physical characteristics of the human body and, most importantly, the human brain. Personality traits are determined by a person's knowledge, his perception and the peculiarities of his physiology. In principle, it is possible to control a person by influencing his brain and perception in general, or, for example, to replace brain impulses with desired ones. It is worth noting that it is possible to influence only on the basis of laws with the help of elementary particles or their systems, and accordingly, there is no possibility to influence from outside our world. In principle, it is possible to control particles from the outside or add/remove particles, but this will lead to a violation of the laws, and, accordingly, can be tracked from the inside. If laws are enforced in the world, then in order to control it from the outside, it is necessary to make changes to these laws, which, in turn, can be discovered in our world. As a result, due to the fact that there are no proven facts of interference in the laws, this excludes the possibility of controlling the world/man from the outside. In addition, there can be no influence of a Supreme intelligence or creature in the primary world, since there can be no external influences (from outside the world), and the influences inside the world are determined by its objects and laws. It is worth noting that all the facts (the fulfillment of laws by particles of the world) indicate that our world is primary.

A person's personality is a society's point of view on a person's worldview and activity from the point of view of ethics and morality (a generalized criterion for public evaluation of a human worldview and activity from the point of view of ethics and morality).

Personality is predetermined at a particular time by particles and the laws of their interaction in the human brain, and throughout life – by the fate of a person.

### Logic and intuition

Logic is the consideration of cause–and-effect relationships by consciousness and the formation of conclusions and their results.

Intuition is the consideration of cause–and-effect relationships and the formation of conclusions and their results unconsciously (without the participation of consciousness).

Men are considered more logical because of a higher level of education.

Television, the Internet and even art books on average harm human development, since the more they use, the less new information he receive. As a result, a person spends his time "in vain". However, truly or even partially scientific means of obtaining information are largely useful, as they contribute to the accumulation of knowledge or, at least, information for reflection that can be used in practice in life. But it is worth recalling that it is necessary to be critical of everything without taking it for granted.

### World of ideas

The world of ideas does not exist as a special form of matter or an additional world, since ideas arise mainly from knowledge, but also partly from perception and features of physiology.

It would be most correct to say that ideas are determined by elementary particles and the laws of their interaction in the human brain.

### Purpose of human life

The activities, actions of a person or any other animal are aimed at satisfying their own needs. The needs of different people may be different due to physiology, ideological attitudes, goals, ethical and moral norms, etc. A person strives for what will bring him more pleasure at a given time and in the future (pleasure theory).

Rational human activity (of any animal) is based only on perception and one's own knowledge, and activity as a whole is also based on physiology.

### The meaning of existence

There is no meaning of existence. The meaning of all objects, systems and elementary particles is the fulfillment of the laws of the world. However, from the point of view of the "laws" ("goals") inherent in a person, we strive for the maximum (best choice) satisfaction of our needs (maximizing pleasures). However, this does not justify our activity to achieve pleasure. In fact, the social contract system protects us at least a little from total chaos due to a conflict of interests.

### Values

Everyone sets values or criteria of pleasure "for himself" depending on what brings him more pleasure (satisfaction). They are determined by particles, the laws of their interaction (world laws), and in a simplified sense – knowledge, perception and physiology of a person or animal.

### Human actions and their consequences

Human actions are predetermined and the consequences of these actions are also predetermined.

In a "simplified" sense, a human makes decisions and generally performs any actions based on his own physical characteristics, and in an even more "simplified" form – based on his knowledge accumulated during his life and the peculiarities of the physical structure of the brain and body.

However, in reality, actions are determined purely based on the dynamics of the elementary particles that make up a human.

### Personality dynamics

The human brain (personality) is dynamic (changes over time). Everything that he perceives changes him and, accordingly, changes his character, goals, worldview and decisions taken as a whole (by and large, we can say that one person at different times is different people). The same can be said about animals, since their brains are arranged in a similar way and are based on the same principles.

### Uniqueness, superiority and merit

Combinations (systems) of elementary particles (object) have the same abilities at the elementary level of representation. At a higher level of representation, which a person usually considers, the abilities are different, since the combinations of elementary particles are different. However, what gave (who gave) the combination of elementary particles (object) these abilities? These are elementary particles that obey laws and change their position in space over time, that is, fate. In fact, properties or abilities are the consequences of the execution of laws by elementary particles.

All objects are equally unique, since the combinations of elementary particles they consist of and their (objects or particles) position in space are unique. Accordingly, it would be wrong (incorrect) to say that "a person is more unique than a stone".

The mind is not something unique. Animals also have minds, but the peculiarities of our (human) physiology, the transfer of experience from generation to generation, the accumulation of knowledge, "accidental" discoveries, and the other aspects of fate allowed humans to become the leader (dominant species) on our planet. A human, in fact, is just "lucky" (as it happened / such is fate) more than others. It is worth noting that the mind is present not only in humans, animals, but also in plants, insects, bacteria, viruses, and even a stone can be considered reasonable (it all depends on the interpretation of the term "mind").The only difference between all objects is how difficult it is to predict their individual characteristics and behavior in general. Due to the fact that a human's behavior and decisions are the most difficult to predict (from the listed classes), he is assigned artificial "peculiarity" and "uniqueness". Humans are still the "dominant" (most successful) combination of elementary particles known on Earth. In fact, human and stone are simply different combinations of elementary particles. This indicates that we are different (have different "abilities"), and not that someone is better or more perfect. As a result, it is at least incorrect to compare the same thing (a combination of elementary particles). If we compare any particular ability (for example, solidity), then it may be better or worse for some of the compared systems (for example, a human or a stone). Perhaps the main result that a human is proud of is his achievements, merits, "uniqueness", "peculiarity", children, "domination", etc., but all this (what every human is proud of) is a consequence of the fact that human / human race are a system of elementary particles that obey the laws of our world, which means that all this is not his merit (such is the merit of fate).

With the available knowledge, we can say that humans most likely "appeared" in the process of evolution. It is worth noting that it is impossible to completely deny the possibility of interference by aliens, which, however, should have appeared in the process of evolution. Accordingly, it is more logical, based on the available data, to consider humans as a consequence of evolution until the opposite is proved.

### Life

Life is a process from the appearance of a system to its disintegration (destruction / death / completion of functioning). Accordingly, not only a human or a living creature can live, but also any system of elementary particles.

### Alive

The alive (life) was born due to a specific combination of particles (objects /molecules). It is worth noting that this is a matter of terminology, who or what to call alive. In any case, the alive appeared during the formation of a specific combination of particles or objects (evolution, mutation, etc.). In my opinion, it is possible to isolate (separate) the alive from the lifeless, but only for classification, and not because something is better or "more perfect" than something else. In fact, the alive and the lifeless are "the same" (the same particles and the laws of their interaction), but due to terminology and classification, these objects were put into different classes.

### Love

Love is the "chemistry" in the brain. For this reason, it is impossible to talk about the presence of a single "soul mate" for a particular human. In principle, "chemistry" always works and one can only judge its "strength". However, the difference in "strength" may not be noticed with a large number of alternatives. In fact, the choice of love is based on a combination of physical, logical, rational, subjective factors. According to it, the "I" makes a choice about which alternative (the consequences of the choice) is better.

### Artificial intelligence

At the current stage of development, artificial intelligence (AI) has not yet been created and there are not even prerequisites for its creation (as far as we know). Everything that now bears the name of artificial intelligence does not have the possibility of independent development, as well as development in principle. As a result, at the moment there is no system capable of learning and self-development. The systems that exist at the moment, usually called AI systems, are in fact automated systems, sometimes having the property of making different (pre-described and prescribed) choices depending on the input and accumulated data. However, such systems are unable to "invent" and implement their own algorithm, which would lead to better consequences than the existing one.

The implementation of real artificial intelligence boils down to the creation of a system based on the principles of human functioning, that is, the system must predict the consequences and choose the best choice according to the goals set.

It is possible to implement an AI system with the available resources, but the key point here is the implementation of a protective system for humans, since in the basic version the system is not limited in actions that can harm humans and humanity. It is not easy to organize a system that is obviously reliable in this aspect, since this modification is unnatural and not logical from the point of view of the system. As a result, the main problem boils down not to the impossibility of creating AI, but to the possibility of the AI system destroying its creator (the impossibility of natural AI control) due to the fact that this (the destruction of humanity) may be the best solution to the task. Even at the current level of science and technology, the potential capabilities and abilities of AI will be much higher than that of humans, which can lead to tragic consequences. The "probability" that a person will survive after creating a fully functional AI is extremely small (tends to zero).

### Organization of the management and resource allocation system

Any system will not suit everyone, since everyone has their own goals that may contradict the goals of someone else. As a result, either a system with common goals is needed, which contradicts the essence of a human, or a system of social contract and lobbying of interests. The best way to organize management is a hierarchical system with the choice by professionals of their representatives. The higher the level in the hierarchy, the more general the problems of the area should be dealt with by the representative. Only a professional can really understand what is going on in his area, and, accordingly, competently defend the interests of his group. As a result, it is possible to create a hierarchical system of councils of professionals of region and groups of regions in order to solve common problems and issues.

# Results

-   everything in the universe consists of elementary particles (quantum photons and quantum gravitons). Their dynamics are predetermined by the laws of interaction;
-   the speed of elementary particles is the same and constant;
-   the space of the world is three-dimensional;
-   space and time are continuous;
-   elementary particles appeared out of nowhere in a very small volume of three-dimensional space of the universe. After that, the Big Bang occurred, without the superluminal inflation of space, which became a reflection of the dynamics of elementary particles;
-   more than 27 billion years have passed since the beginning of the Big Bang without a superluminal inflation of space;
-   elementary particles and the laws of the primary world exist initially, but for a limited period of time;
-   the dynamics of elementary particles is predetermined by fixed laws of their interaction → unambiguity of dynamics → fate;
-   probabilities are just the consequences of conducting a series of experiments with different initial and external conditions. Our universe does not have a probabilistic nature and obeys fixed laws, and therefore has only one fate;
-   quantum photons interact only with quantum gravitons;
-   quantum photons do not interact with each other;
-   quantum gravitons do not interact with each other;
-   there is no control over the world;
-   the world is fully cognizable;
-   according to the available facts, our world is primary;
-   there is a guarantee to determine the impact on our world from the outside;
-   the properties of a system are determined by the properties of its parts;
-   there is no appearance of new or disappearance/change of existing elementary particles and laws;
-   there is a redistribution of elementary particles between systems, but there is no transformation of one system into another;
-   the world is limited by elementary particles and the laws of their interaction;
-   there is no complete forecast of the future;
-   Immobile frame of reference (ImFR) are equal and can be described by general laws. Inertial reference frames are in general unequal and our universe has an absolute reference frame - ImFR;
-   there is no wave-particle dualism, and all effects are caused purely by particle dynamics;
-   active observation of elementary particles/systems changes their state, while passive observation does not. Interact an elementary particle/system with other elementary particles/systems → change the dynamics of an elementary particle/elementary particles entering the system. The so-called "quantum effects" are solely a consequence of intervention in/impact on the dynamics of elementary particle systems. Consciousness/passive observation does not affect the dynamics of elementary particle systems. Interference, diffraction, polarization and other sources of "quantum effects" are the result of the re-emission (with a change in the characteristics and directions of motion) by atoms of slits/glasses/mirrors/polarizers of passing/interacting with them by particles. Therefore, violations of Bell's inequality are easily explained classically without violating locality/realism;
-   there are no stable systems of elementary particles;
-   quantum gravitons may be emit not uniformly to all sides of three-dimensional space, for example, functioning of [[SMBH.en|SMBH]] with [[Relativistic jet.en|relativistic jets]] - [[Blazar.en|blazars]];
-   the energy is determined by the elementary particles of the system/object;
-   human is a set of elementary particles;
- matter is not a product of consciousness;
- the purpose of a human's life is to satisfy his own needs;
- there is no sense of existence;
- the human brain (personality) is dynamic (changes over time);
- there is no separate world of ideas;
- life is a process from the appearance to the disintegration of the system;
- love is the "chemistry" of the brain (a combination of physical factors);
- there is no uniqueness or superiority (equally for all objects);
- it is possible to create artificial intelligence;
- there are no parallel worlds.

Our universe is completely determined by elementary particles moving at the same speed relative to an absolute frame of reference, the laws of their interaction, three-dimensional continuous space, as well as global laws that determine its beginning.

All other conclusions are consequences. 

For example, a continuous "arrow of time" is a consequence of the movement of elementary particles at the same speed. The "arrow of time" was "released" (originates) at the moment of the appearance of elementary particles in the universe. Its "flight" (the process of increasing the value of time) reflects the entire dynamics of the movement of elementary particles from the Big Bang, the formation/death of galaxies, stars, planets to the Big freeze and Big scattering (although the end of the Big scattering process is potentially unlimited in time).

## Afterword

### Key distinguishing features of the theory of everything

Each theory has a number of key distinctive features that form its basis and separate it from other theories.

Let's describe the key distinctive features of the theory of everything:

- the radiation period of the caesium-133 atom depends on the speed of motion relative to ImFR/IFR/zero shift of the relic radiation(zero dipole anisotropy). In general, any processes for elementary particle systems depend on the speed of motion relative to the ImFR (from the lifetime of particles to atoms and macro objects). Here the peculiarity lies in the definition of the term "Time" different from the one that became the basis of [[GTR.en|GTR]]
- a quantum graviton is an elementary particle, not a deformation of space-time by mass. Here the peculiarity is in understanding the source of gravity
- the particles of the Standard Model do not transform, but there is a redistribution of the elementary particles of which they consist. The peculiarity is in the understanding that elementary particles are stable and cannot transform/emit/absorb
- the dynamics of elementary particles is predetermined (fate). The peculiarity is in the understanding that probabilities are the consequences of errors in experimental conditions. And if there are laws in the world, then their consequences are unambiguous
- the impact on elementary particles or systems changes their dynamics. Now all have begun to partially understand this feature as the cause of the "observer effect" and others
- all elementary particles are corpuscles. Elementary particles have no wave properties. The peculiarity is in understanding the redistribution/re-emission of elementary particles in space, and not in the superposition of waves. For example, it is impossible to neutralize one photon beam with other (which are in opposite phase to each other), which is realistic from the point of view of wave theory

As we can see, there are not so many key distinguishing features in the theory of everything. However, this allowed us to form a holistic physical theory describing everything in our universe/world.